(window.webpackJsonp=window.webpackJsonp||[]).push([[21],{375:function(e,t,_){"use strict";_.r(t);var n=_(44),o=Object(n.a)({},(function(){var e=this,t=e.$createElement,_=e._self._c||t;return _("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[_("h2",{attrs:{id:"概述"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#概述"}},[e._v("#")]),e._v(" 概述")]),e._v(" "),_("p",[e._v(" 该文档用于介绍OpenNCC Software Development Kit (SDK) 并且包含了启动，运行及开发的所有必要信息。")]),e._v(" "),_("h2",{attrs:{id:"sdk结构"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#sdk结构"}},[e._v("#")]),e._v(" SDK结构")]),e._v(" "),_("table",[_("thead",[_("tr",[_("th",[e._v("目录")]),e._v(" "),_("th",[e._v("内容")])])]),e._v(" "),_("tbody",[_("tr",[_("td",[e._v("./Platform")]),e._v(" "),_("td",[e._v("包含不同平台生成运行环境的脚本。")])]),e._v(" "),_("tr",[_("td",[e._v("./SDK/docs")]),e._v(" "),_("td",[e._v("包含SDK相关介绍和文档。")])]),e._v(" "),_("tr",[_("td",[e._v("./SDK/Drivers")]),e._v(" "),_("td",[e._v("包含不同平台所必须安装的驱动。")])]),e._v(" "),_("tr",[_("td",[e._v("./SDK/Example")]),e._v(" "),_("td",[e._v("包含SDK的相关例程。")])]),e._v(" "),_("tr",[_("td",[e._v("./SDK/Source")]),e._v(" "),_("td",[e._v("包含固件，模型及SDK库文件。")])]),e._v(" "),_("tr",[_("td",[e._v("./SDK/Tools")]),e._v(" "),_("td",[e._v("包含相关的模型转换及编译工具。")])]),e._v(" "),_("tr",[_("td",[e._v("./Viewer")]),e._v(" "),_("td",[e._v("包含已编译的Viewer及QT源码。")])])])]),e._v(" "),_("h2",{attrs:{id:"支持的产品及平台"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#支持的产品及平台"}},[e._v("#")]),e._v(" 支持的产品及平台")]),e._v(" "),_("p",[e._v("SDK支持的产品如下：")]),e._v(" "),_("ul",[_("li",[_("p",[e._v("OpenNCC DK")])]),e._v(" "),_("li",[_("p",[e._v("OpenNCC Lite")])]),e._v(" "),_("li",[_("p",[e._v("OpenNCC USB")])])]),e._v(" "),_("p",[e._v("SDK支持的平台如下：")]),e._v(" "),_("ul",[_("li",[e._v("Ubuntu 16.04, Ubuntu 18.04")]),e._v(" "),_("li",[e._v("Windows 10")]),e._v(" "),_("li",[e._v("Raspberry Pi（树莓派）")]),e._v(" "),_("li",[e._v("Arm Linux(需提供工具链交叉编译)")])]),e._v(" "),_("p",[e._v("SDK支持的语言如下：")]),e._v(" "),_("ul",[_("li",[e._v("C/C++")]),e._v(" "),_("li",[e._v("Python3.5、Python3.7")])]),e._v(" "),_("h3",{attrs:{id:"sdk开发包目录结构"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#sdk开发包目录结构"}},[e._v("#")]),e._v(" SDK开发包目录结构")]),e._v(" "),_("table",[_("thead",[_("tr",[_("th",[e._v("目录")]),e._v(" "),_("th",{staticStyle:{"text-align":"left"}},[e._v("内容概要")])])]),e._v(" "),_("tbody",[_("tr",[_("td",[e._v("Example/How_to"),_("br"),e._v("/How_to_use_sdk")]),e._v(" "),_("td",{staticStyle:{"text-align":"left"}},[e._v("示例程序，如何在项目中使用SDK库。")])]),e._v(" "),_("tr",[_("td",[e._v("Example/How_to"),_("br"),e._v("/Capture_video")]),e._v(" "),_("td",{staticStyle:{"text-align":"left"}},[e._v("示例程序，使用SDK库获取视频流。")])]),e._v(" "),_("tr",[_("td",[e._v("Example/How_to"),_("br"),e._v("/Load_a_model")]),e._v(" "),_("td",{staticStyle:{"text-align":"left"}},[e._v("示例程序，使用SDK库下载一个Blob格式的深度学习模型。")])]),e._v(" "),_("tr",[_("td",[e._v("Example/How_to"),_("br"),e._v("/work_with_multiple_models")]),e._v(" "),_("td",{staticStyle:{"text-align":"left"}},[e._v("示例程序，二级模型的应用。")])]),e._v(" "),_("tr",[_("td",[e._v("Example/How_to"),_("br"),e._v("/Python_demo")]),e._v(" "),_("td",{staticStyle:{"text-align":"left"}},[e._v("Python的相关示例。")])]),e._v(" "),_("tr",[_("td",[e._v("Example/Linkage_demo"),_("br"),e._v("/work with AlwaysAI "),_("br"),e._v("/pedestrian_tracking_demo")]),e._v(" "),_("td",{staticStyle:{"text-align":"left"}},[e._v("人脸模型，使用AlwaysAI解析结果显示，并统计通过识别区域的人数。")])]),e._v(" "),_("tr",[_("td",[e._v("Example/Linkage_demo"),_("br"),e._v("/work_with_OpenVINO"),_("br"),e._v("/human_pose_estimation_demo")]),e._v(" "),_("td",{staticStyle:{"text-align":"left"}},[e._v("人体骨骼模型，使用OpenVINO解析结果显示。")])]),e._v(" "),_("tr",[_("td",[e._v("Example/Linkage_demo"),_("br"),e._v("/work_with_OpenVINO"),_("br"),e._v("/interactive_face_detection_demo")]),e._v(" "),_("td",{staticStyle:{"text-align":"left"}},[e._v("人脸、年龄、性别、心情模型，使用OpenVINO解析结果显示。")])]),e._v(" "),_("tr",[_("td",[e._v("Example/Linkage_demo"),_("br"),e._v("/work_with_PaddlePaddle")]),e._v(" "),_("td",{staticStyle:{"text-align":"left"}},[e._v("OCR文字识别示例程序，包含OpenNCC PaddlePaddle-OCR 仓库链接。")])]),e._v(" "),_("tr",[_("td",[e._v("Tools/myriad_compiler")]),e._v(" "),_("td",{staticStyle:{"text-align":"left"}},[e._v("IR文件转换成Blob文件工具")])]),e._v(" "),_("tr",[_("td",[e._v("Tools/deployment")]),e._v(" "),_("td",{staticStyle:{"text-align":"left"}},[e._v("权限部署脚本")])])])]),e._v(" "),_("h2",{attrs:{id:"已集成的ai模型"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#已集成的ai模型"}},[e._v("#")]),e._v(" 已集成的AI模型")]),e._v(" "),_("table",[_("thead",[_("tr",[_("th",[e._v("模型类别")]),e._v(" "),_("th",[e._v("名称")]),e._v(" "),_("th",[e._v("简介")]),e._v(" "),_("th",[e._v("其他参考")])])]),e._v(" "),_("tbody",[_("tr",[_("td",[e._v("物体分类")]),e._v(" "),_("td",[e._v("classification-fp16")]),e._v(" "),_("td",[e._v("ssd_mobilenet_v1_coco model can detect almost 90 objects")]),e._v(" "),_("td",[_("a",{attrs:{href:"https://docs.openvinotoolkit.org/latest/omz_models_public_ssd_mobilenet_v1_coco_ssd_mobilenet_v1_coco.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),_("OutboundLink")],1)])]),e._v(" "),_("tr",[_("td",[e._v("人脸、人形检测")]),e._v(" "),_("td",[e._v("face-detection-adas-0001-fp16")]),e._v(" "),_("td",[e._v("Face detector for driver monitoring and similar scenarios. The network features a default MobileNet backbone that includes depth-wise convolutions to reduce the amount of computation for the 3x3 convolution block")]),e._v(" "),_("td",[_("a",{attrs:{href:"http://docs.openvinotoolkit.org/2019_R1.1/_face_detection_adas_0001_description_face_detection_adas_0001.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),_("OutboundLink")],1)])]),e._v(" "),_("tr",[_("td"),e._v(" "),_("td",[e._v("face-detection-retail-0004-fp16")]),e._v(" "),_("td",[e._v("Face detector based on SqueezeNet light (half-channels) as a backbone with a single SSD for indoor/outdoor scenes shot by a front-facing camera")]),e._v(" "),_("td",[_("a",{attrs:{href:"https://docs.openvinotoolkit.org/2019_R1.1/_face_detection_retail_0004_description_face_detection_retail_0004.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),_("OutboundLink")],1)])]),e._v(" "),_("tr",[_("td"),e._v(" "),_("td",[e._v("face-person-detection-retail-0002-fp16")]),e._v(" "),_("td",[e._v("This is a pedestrian detector based on backbone with hyper-feature + R-FCN for the Retail scenario")]),e._v(" "),_("td",[_("a",{attrs:{href:"https://docs.openvinotoolkit.org/2019_R1.1/person-detection-retail-0002.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),_("OutboundLink")],1)])]),e._v(" "),_("tr",[_("td"),e._v(" "),_("td",[e._v("person-detection-retail-0013-fp16")]),e._v(" "),_("td",[e._v("This is a pedestrian detector for the Retail scenario. It is based on MobileNetV2-like backbone that includes depth-wise convolutions to reduce the amount of computation for the 3x3 convolution block")]),e._v(" "),_("td",[_("a",{attrs:{href:"https://docs.openvinotoolkit.org/2019_R1.1/_person_detection_retail_0013_description_person_detection_retail_0013.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),_("OutboundLink")],1)])]),e._v(" "),_("tr",[_("td"),e._v(" "),_("td",[e._v("pedestrian-detection-adas-0002-fp16")]),e._v(" "),_("td",[e._v("Pedestrian detection network based on SSD framework with tuned MobileNet v1 as a feature extractor.")]),e._v(" "),_("td",[_("a",{attrs:{href:"https://docs.openvinotoolkit.org/2019_R1.1/_pedestrian_detection_adas_0002_description_pedestrian_detection_adas_0002.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),_("OutboundLink")],1)])]),e._v(" "),_("tr",[_("td",[e._v("人车、自行车")]),e._v(" "),_("td",[e._v("person-vehicle-bike-detection-crossroad-0078-fp16")]),e._v(" "),_("td",[e._v("Person/Vehicle/Bike detector is based on SSD detection architecture, RMNet backbone, and learnable image downscale block (like person-vehicle-bike-detection-crossroad-0066, but with extra pooling)")]),e._v(" "),_("td",[_("a",{attrs:{href:"https://docs.openvinotoolkit.org/2019_R1.1/_person_vehicle_bike_detection_crossroad_0078_description_person_vehicle_bike_detection_crossroad_0078.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),_("OutboundLink")],1)])]),e._v(" "),_("tr",[_("td"),e._v(" "),_("td",[e._v("pedestrian-and-vehicle-detector-adas-0001-fp16")]),e._v(" "),_("td",[e._v("Pedestrian and vehicle detection network based on MobileNet v1.0 + SSD.")]),e._v(" "),_("td",[_("a",{attrs:{href:"https://docs.openvinotoolkit.org/2019_R1.1/_pedestrian_and_vehicle_detector_adas_0001_description_pedestrian_and_vehicle_detector_adas_0001.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),_("OutboundLink")],1)])]),e._v(" "),_("tr",[_("td",[e._v("车辆检测")]),e._v(" "),_("td",[e._v("vehicle-detection-adas-0002-fp16")]),e._v(" "),_("td",[e._v("This is a vehicle detection network based on an SSD framework with tuned MobileNet v1 as a feature extractor.")]),e._v(" "),_("td",[_("a",{attrs:{href:"http://docs.openvinotoolkit.org/2019_R1.1/_vehicle_detection_adas_0002_description_vehicle_detection_adas_0002.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),_("OutboundLink")],1)])]),e._v(" "),_("tr",[_("td",[e._v("口罩检测")]),e._v(" "),_("td",[e._v("Mask-detect-fp16")]),e._v(" "),_("td",[e._v("Mask detect")]),e._v(" "),_("td",[e._v("Under license")])]),e._v(" "),_("tr",[_("td",[e._v("车牌识别")]),e._v(" "),_("td",[e._v("vehicle-license-plate-detection-barrier-0106-fp16")]),e._v(" "),_("td",[e._v('This is a MobileNetV2 + SSD-based vehicle and (Chinese) license plate detector for the "Barrier" use case.')]),e._v(" "),_("td",[_("a",{attrs:{href:"https://docs.openvinotoolkit.org/2019_R1.1/_vehicle_license_plate_detection_barrier_0106_description_vehicle_license_plate_detection_barrier_0106.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),_("OutboundLink")],1)])]),e._v(" "),_("tr",[_("td",[e._v("人脸属性")]),e._v(" "),_("td",[e._v("interactive_face_detection_demo")]),e._v(" "),_("td",[e._v("This demo executes four parallel infer requests for the Age/Gender Recognition, Head Pose Estimation, Emotions Recognition, and Facial Landmarks Detection networks that run simultaneously")]),e._v(" "),_("td",[_("a",{attrs:{href:"https://docs.openvinotoolkit.org/2019_R1.1/_inference_engine_samples_interactive_face_detection_demo_README.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),_("OutboundLink")],1)])]),e._v(" "),_("tr",[_("td",[e._v("人体骨骼提取")]),e._v(" "),_("td",[e._v("human-pose-estimation-0001-fp16")]),e._v(" "),_("td",[e._v("A multi-person 2D pose estimation network (based on the OpenPose approach) with tuned MobileNet v1 as a feature extractor.")]),e._v(" "),_("td",[_("a",{attrs:{href:"https://docs.openvinotoolkit.org/2019_R1.1/_human_pose_estimation_0001_description_human_pose_estimation_0001.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),_("OutboundLink")],1)])])])]),e._v(" "),_("h2",{attrs:{id:"openvino-安装和使用"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#openvino-安装和使用"}},[e._v("#")]),e._v(" OpenVINO 安装和使用")]),e._v(" "),_("p",[e._v(" 在端侧部署一个深度学习模型，需要将一个训练完成的模型经过针对VPU特性的模型优化和转换，以达到较高的运行性能。OpenNCC兼容OpenVINO的工具集和模型格式，需要依赖Intel OpenVINO的模型优化器来完成模型优化和转换成Blob格式。使用OpenNCC SDK时需要安装OpenVINO的两种情况如下：")]),e._v(" "),_("div",{staticClass:"language- extra-class"},[_("pre",[_("code",[e._v("如果需要自行转换训练好的模型，那么需要安装OpenVINO，来运行模型优化器。\n当OpenVINO运行在与OpenVINO推理引擎的混合模式时，也需要OpenVINO支持。\n")])])]),_("h3",{attrs:{id:"下载并安装openvino"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#下载并安装openvino"}},[e._v("#")]),e._v(" 下载并安装OpenVINO")]),e._v(" "),_("p",[e._v(" OpenNCC 目前支持OpenVINO版本：2020.3.194,"),_("RouterLink",{attrs:{to:"/ch/7_OpenvinoInstall_ch.html"}},[e._v("OpenVINO安装教程")])],1),e._v(" "),_("h3",{attrs:{id:"intel-free模型下载"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#intel-free模型下载"}},[e._v("#")]),e._v(" Intel Free模型下载")]),e._v(" "),_("p",[e._v(" OpenNCC支持OpenVINO下生产的模型，Intel有大量免费训练好的模型供学习参考和评测。当我们安装完成OpenVINO后，可以使用Intel下载工具下载模型集合。模型下载工具路径：openvino/deployment_tools/tools/model_downloader/downloader.py ,常用命令如下：")]),e._v(" "),_("p",[e._v("查看全部可下载的模型："),_("code",[e._v("./downloader.py --print")])]),e._v(" "),_("p",[e._v("下载指定的模型："),_("code",[e._v("./downloader.py --name *")])]),e._v(" "),_("p",[e._v("例如下载一个人脸检测模型 ："),_("code",[e._v("./downloader.py --name face-detection-adas-0001-fp16")])]),e._v(" "),_("p",[_("img",{attrs:{src:"/openncc/docimg/ch/SoftManualF1.png",alt:"F1"}})]),e._v(" "),_("h3",{attrs:{id:"模型的优化和格式转换"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#模型的优化和格式转换"}},[e._v("#")]),e._v(" 模型的优化和格式转换")]),e._v(" "),_("p",[e._v(" 当我们需要将一个训练好模型部署到OpenNCC时，需要对模型进行优化和转换。安装完成OpenVINO后，可通过模型优化工具 "),_("code",[e._v("/opt/intel/openvino/deployment_tools/model_optimizer/mo.py")]),e._v(" 进行模型优化，具体文档见Intel官方文档：  "),_("a",{attrs:{href:"https://docs.openvinotoolkit.org/2020.3/_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Model Optimizer Developer Guide"),_("OutboundLink")],1),e._v(" 。")]),e._v(" "),_("p",[e._v("优化完成模型后，需要进行模型转换到Blob格式，才能在OpenNCC上进行部署。在OpenVINO安装目录 "),_("code",[e._v("/opt/intel/openvino/deployment_tools/inference_engine/lib/intel64")]),e._v("下的myriad_compile工具，使用方法如下：\n命令行终端下输入："),_("code",[e._v("/opt/intel/openvino_2020.3.194/deployment_tools/inference_engine/lib/intel64/myriad_compile -m input_xxx-fp16.xml -o output_xxx.blob -VPU_MYRIAD_PLATFORM VPU_MYRIAD_2480 -VPU_NUMBER_OF_SHAVES 6 -VPU_NUMBER_OF_CMX_SLICES 6")]),e._v(" , 完成格式转换后，可在OpenNCC上部署模型，可参考：ncc_SDK/Samples/How_to/load a model，或者使用OpenView界面程序添加模型来部署测试。")]),e._v(" "),_("h2",{attrs:{id:"openncc运行机制"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#openncc运行机制"}},[e._v("#")]),e._v(" OpenNCC运行机制")]),e._v(" "),_("p",[e._v(" 从一个模型训练环境到嵌入式部署，是一个非常重要的工作，需要对深度学习的框架掌握，如常用的：Caffe*, TensorFlow*, MXNet*, Kaldi* 等。此外掌握部署的嵌入式平台非常重要，需要了解平台性能，系统架构特点，结合平台特点需要对训练的模型框架进行优化，并最后调优移植部署到嵌入式平台。OpenNCC专注于深度学习模型的快速部署，兼容Intel OpenVINO，并针对嵌入式图形图像应用场景，在端侧完成了从2MP到20MP不同分辨率传感器集成，端侧实现了可部署专业级别的ISP，可将OpenVINO优化转换后的模型文件动态下载到端侧OpenNCC相机，实现深度学习模型的快速部署。同时OpenNCC设计了独立工作模式、混合开发模式和协处理计算棒模式来适配不同的工作应用场景。")]),e._v(" "),_("h3",{attrs:{id:"openncc独立模式"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#openncc独立模式"}},[e._v("#")]),e._v(" OpenNCC独立模式")]),e._v(" "),_("p",[e._v(" 独立模式下，OpenNCC独立运行一个深度学习模型，并将推理结果通过OpenNCC SDK API反馈给用户。")]),e._v(" "),_("p",[e._v("应用程序部署流程如下图：")]),e._v(" "),_("p",[_("img",{attrs:{src:"/openncc/docimg/ch/SoftManualF2.png",alt:"F"}}),e._v("\n按照OpenVINO文档，为特定的训练框架"),_("a",{attrs:{href:"https://docs.openvinotoolkit.org/2020.3/_docs_MO_DG_prepare_model_Config_Model_Optimizer.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("配置模型优化器(Configure Model Optimizer)"),_("OutboundLink")],1)]),e._v(" "),_("p",[_("a",{attrs:{href:"https://docs.openvinotoolkit.org/2020.3/_docs_IE_DG_Introduction.html#MO",target:"_blank",rel:"noopener noreferrer"}},[e._v("运行模型优化器(Model Optimizer)"),_("OutboundLink")],1),e._v("，基于训练好的网络拓扑、权值和偏差值等可选参数产生一个优化后的IR文件，IR是一对描述整个模型的文件，包括.xml文件--拓扑文件-描述网络拓扑的XML文件，以及.bin文件--训练后的数据文件-一个包含权重并偏置二进制数据的.bin文件，然后再运行myriad_compile将IR文件生成BLOB文件。")]),e._v(" "),_("p",[e._v(" 在应用程序上，集成使用OpenNCC SDK下载优化完成后的BLOB模型文件，见SDK下"),_("code",[e._v("Example/How_to/Load_a_model")]),e._v("的演示程序。")]),e._v(" "),_("p",[e._v(" OpenNCC View是集成了OpenNCC SDK的带操作界面的应用演示程序，也可以使用OpenView来部署模型，获取测试结果。OpenNCC View 使用文档。由于不同的深度模型有差异化的推理输出结果，OpenNCC SDK对不同格式结果支持在不断增加中，如果用户无法在SDK下找到合适的后处理解析模型，需要自己参考"),_("code",[e._v("Example/How_to/Load_a_model")]),e._v("并结合自己应用场景来编写后处理代码。")]),e._v(" "),_("h4",{attrs:{id:"二级模型运行支持"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#二级模型运行支持"}},[e._v("#")]),e._v(" 二级模型运行支持")]),e._v(" "),_("p",[e._v("考虑到端侧算力，目前SDK多级模型支持到两级模型级联，如图：")]),e._v(" "),_("p",[_("img",{attrs:{src:"/openncc/docimg/ch/SoftManualF10.jpg",alt:"F"}})]),e._v(" "),_("p",[e._v("第一级模型必须为目标检测或者分类模型，且输出定义如下：\n"),_("img",{attrs:{src:"/openncc/docimg/ch/SoftManualF11.jpg",alt:"F"}})]),e._v(" "),_("p",[e._v("推理流程：")]),e._v(" "),_("p",[e._v("1）图像先经过Pre-cv[1] ，把原图scale到一级模型输入大小，并做相应的格式转换，然后做一级模型推理计算，并且把一级推理结果输出到Pre-cv[2].\n2) Pre-cv[2] 模块解析第一级模型的推理结果，把符合条件的label和conf的检测目标，根据坐标起点(x_min, y_min), 终点(x_max,y_max)从\n原图crop和scale到二级模型输入大小，并做相应的格式转换，进入第二级模型推理。")]),e._v(" "),_("p",[e._v("3)最后把一级模型和全部的二级模型推理结果打包在一起输出。")]),e._v(" "),_("p",[e._v("模型输出解析（图示参数配置为，有效label：2,3，conf=0.8）：")]),e._v(" "),_("p",[_("img",{attrs:{src:"/openncc/docimg/ch/SoftManualF12.png",alt:"F"}})]),e._v(" "),_("p",[e._v("示例程序："),_("code",[e._v("Example/How_to/work_with_multiple_models")]),e._v(",第一级模型为车辆和车牌检测，第二级模型是车牌检测，设置有效的label为2。")]),e._v(" "),_("p",[e._v("基于第一级的检测结果，适当微调第一级的检测坐标，有利于识别:")]),e._v(" "),_("p",[e._v("*起点向左上方微调（startXAdj，startYAdj ）")]),e._v(" "),_("p",[e._v("*底点向右下方微调（endXAdj，endYAdj）")]),e._v(" "),_("p",[e._v("cnn2PrmSet.startXAdj  = -5;")]),e._v(" "),_("p",[e._v("cnn2PrmSet.startYAdj  = -5;")]),e._v(" "),_("p",[e._v("cnn2PrmSet.endXAdj   = 5;")]),e._v(" "),_("p",[e._v("cnn2PrmSet.endYAdj   = 5;")]),e._v(" "),_("h3",{attrs:{id:"openncc-混合模式"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#openncc-混合模式"}},[e._v("#")]),e._v(" OpenNCC 混合模式")]),e._v(" "),_("p",[e._v(" 当需要解决一些复杂应用场景，需要多个网络模型组合处理、OpenNCC端侧计算性能无法满足、或者端侧处理完成后需要到边缘侧集中后处理时，往往需要进行系统扩增。将实时性诉求高的模型运行在OpenNCC端侧，其他模型运行在后处理边缘机或云端。")]),e._v(" "),_("p",[e._v("如图，Model-1运行在OpenNCC端侧，完成对视频流的前处理。OpenNNC将一级处理模型结果返回用户应用程序，Model-1和Model-2完全运行于OpenVINO推理引擎下，实现后续处理。")]),e._v(" "),_("p",[_("img",{attrs:{src:"/openncc/docimg/ch/SoftManualF3.png",alt:"F"}}),e._v(" "),_("code",[e._v("Examples/Linkage_demo/work_with_OpenVINO")]),e._v(" 演示了如何让OpenNCC和Host PC上OpenVINO组合实现一个分布式AI系统。")]),e._v(" "),_("h3",{attrs:{id:"协处理计算棒模式"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#协处理计算棒模式"}},[e._v("#")]),e._v(" 协处理计算棒模式")]),e._v(" "),_("p",[e._v(" OpenNCC的协处理模式，类似与Intel NCS2计算棒。这种工作模式下，OpenNCC的视觉传感器不工作，用户可以单独使用OpenNCC 来实现完全兼容OpenVINO环境。OpenVINO典型的深度学习模型部署流程如下：\n"),_("img",{attrs:{src:"/openncc/docimg/ch/SoftManualF4.png",alt:"F"}})]),e._v(" "),_("p",[e._v("按照OpenVINO文档，为特定的训练框架"),_("a",{attrs:{href:"https://docs.openvinotoolkit.org/2020.3/_docs_MO_DG_prepare_model_Config_Model_Optimizer.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("配置模型优化器(Configure Model Optimizer)"),_("OutboundLink")],1),e._v("产生一个优化后的IR文件，基于训练好的网络拓扑、权值和偏差值等可选参数。")]),e._v(" "),_("p",[e._v("将优化生成的IR文件下载到OpenNCC上运行"),_("a",{attrs:{href:"https://docs.openvinotoolkit.org/2020.3/_docs_IE_DG_Introduction.html#IE",target:"_blank",rel:"noopener noreferrer"}},[e._v("推理引擎(Inference Engine)"),_("OutboundLink")],1),e._v("，具体参考OpenVINO文档："),_("a",{attrs:{href:"https://docs.openvinotoolkit.org/2019_R1.1/_inference_engine_samples_validation_app_README.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Inference Engine validation application"),_("OutboundLink")],1),e._v(" 和 "),_("a",{attrs:{href:"https://docs.openvinotoolkit.org/2020.3/_docs_IE_DG_Samples_Overview.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("sample applications"),_("OutboundLink")],1),e._v(" 。\n将"),_("code",[e._v("Source/Firmware/fw /usb-ma2x8x.mvcmd")]),e._v("复制并且替换openvino安装目录下的openvino/inference_engine/lib/intel64/usb-ma2x8x.mvcmd.(备注：替换前必须备份usb-ma2x8x.mvcmd，使用NCS2推理时需要恢复该文件)")]),e._v(" "),_("h3",{attrs:{id:"独立模式和协处理模式区别"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#独立模式和协处理模式区别"}},[e._v("#")]),e._v(" 独立模式和协处理模式区别")]),e._v(" "),_("p",[e._v(" 如下图右侧是OpenNCC的独立模式，左侧是OpenNCC的协处理模式(类同Intel NCS2)。")]),e._v(" "),_("p",[_("img",{attrs:{src:"/openncc/docimg/ch/SoftManualF5.png",alt:"F"}}),e._v("\n当我们需要部署一个基于视觉的深度学习模型时，首先我们需要获取一个高质量的视频流，然后运行推理引擎来把输入的图像数据进行计算，最后输出结果。左侧的协处理模式，我们需要一个OpenNCC 或者Intel NCS2实现端侧推理，同时我们需要从一个摄像机获取视频流，并将视频帧通过USB发送给OpenNCC。而右侧的独立模式，不需要额外的摄像机来获取视频流，我们只需要将模型下载到OpenNCC后，就可以获取到推演结果。")]),e._v(" "),_("p",[e._v("参考OpenVINO官网：https://docs.openvinotoolkit.org/")])])}),[],!1,null,null,null);t.default=o.exports}}]);