<!DOCTYPE html>
<html lang="English">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Overview | OpenNCC Docs</title>
    <meta name="generator" content="VuePress 1.8.2">
    
    <meta name="description" content="Open AI Camera">
    
    <link rel="preload" href="/openncc/assets/css/0.styles.a0bcdeaa.css" as="style"><link rel="preload" href="/openncc/assets/js/app.92ec51d4.js" as="script"><link rel="preload" href="/openncc/assets/js/2.bef35a51.js" as="script"><link rel="preload" href="/openncc/assets/js/11.057199e2.js" as="script"><link rel="prefetch" href="/openncc/assets/js/10.476ef782.js"><link rel="prefetch" href="/openncc/assets/js/12.ba397f51.js"><link rel="prefetch" href="/openncc/assets/js/13.f6f26a71.js"><link rel="prefetch" href="/openncc/assets/js/14.aa0cf5bd.js"><link rel="prefetch" href="/openncc/assets/js/15.f7699c14.js"><link rel="prefetch" href="/openncc/assets/js/16.e9b2b8ce.js"><link rel="prefetch" href="/openncc/assets/js/17.ab6a5284.js"><link rel="prefetch" href="/openncc/assets/js/18.6bd5b3ac.js"><link rel="prefetch" href="/openncc/assets/js/19.6a4f8811.js"><link rel="prefetch" href="/openncc/assets/js/20.98eb93f3.js"><link rel="prefetch" href="/openncc/assets/js/21.0fb2149e.js"><link rel="prefetch" href="/openncc/assets/js/22.601d034a.js"><link rel="prefetch" href="/openncc/assets/js/23.e4e6a9a3.js"><link rel="prefetch" href="/openncc/assets/js/24.b6ea03d5.js"><link rel="prefetch" href="/openncc/assets/js/25.e889ad31.js"><link rel="prefetch" href="/openncc/assets/js/26.ad699543.js"><link rel="prefetch" href="/openncc/assets/js/27.8e57c10f.js"><link rel="prefetch" href="/openncc/assets/js/28.ad251330.js"><link rel="prefetch" href="/openncc/assets/js/29.d2238b47.js"><link rel="prefetch" href="/openncc/assets/js/3.33041445.js"><link rel="prefetch" href="/openncc/assets/js/30.05b368dd.js"><link rel="prefetch" href="/openncc/assets/js/4.e7c996f5.js"><link rel="prefetch" href="/openncc/assets/js/5.6eff8140.js"><link rel="prefetch" href="/openncc/assets/js/6.17d5dd20.js"><link rel="prefetch" href="/openncc/assets/js/7.51eccf5b.js"><link rel="prefetch" href="/openncc/assets/js/8.4fe559b3.js"><link rel="prefetch" href="/openncc/assets/js/9.edef11f0.js">
    <link rel="stylesheet" href="/openncc/assets/css/0.styles.a0bcdeaa.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/openncc/" class="home-link router-link-active"><!----> <span class="site-name">OpenNCC Docs</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="https://www.openncc.com" target="_blank" rel="noopener noreferrer" class="nav-link external">
  OpenNCC
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="https://github.com/EyecloudAi/openncc" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="https://docs.openvinotoolkit.org/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  OpenVINO
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Select language" class="dropdown-title"><span class="title">Languages</span> <span class="arrow down"></span></button> <button type="button" aria-label="Select language" class="mobile-dropdown-title"><span class="title">Languages</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/openncc/5_Software_Manual.html" aria-current="page" class="nav-link router-link-exact-active router-link-active">
  English
</a></li><li class="dropdown-item"><!----> <a href="/openncc/ch/" class="nav-link">
  中文
</a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="https://www.openncc.com" target="_blank" rel="noopener noreferrer" class="nav-link external">
  OpenNCC
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="https://github.com/EyecloudAi/openncc" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="https://docs.openvinotoolkit.org/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  OpenVINO
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Select language" class="dropdown-title"><span class="title">Languages</span> <span class="arrow down"></span></button> <button type="button" aria-label="Select language" class="mobile-dropdown-title"><span class="title">Languages</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/openncc/5_Software_Manual.html" aria-current="page" class="nav-link router-link-exact-active router-link-active">
  English
</a></li><li class="dropdown-item"><!----> <a href="/openncc/ch/" class="nav-link">
  中文
</a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><a href="/openncc/1_Introduction.html" class="sidebar-link">Introduction of OpenNCC</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/openncc/1_Introduction.html#introduction" class="sidebar-link">Introduction</a></li><li class="sidebar-sub-header"><a href="/openncc/1_Introduction.html#functions" class="sidebar-link">Functions</a></li><li class="sidebar-sub-header"><a href="/openncc/1_Introduction.html#openncc-series" class="sidebar-link">OpenNCC Series</a></li></ul></li><li><a href="/openncc/2_HardwareManual.html" class="sidebar-link">OpenNCC Hardware Manual</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/openncc/2_HardwareManual.html#hardware-specifications" class="sidebar-link">Hardware specifications</a></li><li class="sidebar-sub-header"><a href="/openncc/2_HardwareManual.html#unboxing-show" class="sidebar-link">Unboxing show</a></li><li class="sidebar-sub-header"><a href="/openncc/2_HardwareManual.html#start-up-hardware" class="sidebar-link">Start-up hardware</a></li></ul></li><li><a href="/openncc/3_GettingStart.html" class="sidebar-link">OpenNCC Getting Start</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/openncc/3_GettingStart.html#preparatory-work" class="sidebar-link">Preparatory work</a></li><li class="sidebar-sub-header"><a href="/openncc/3_GettingStart.html#quick-start-to-linux" class="sidebar-link">Quick Start to Linux</a></li><li class="sidebar-sub-header"><a href="/openncc/3_GettingStart.html#quick-start-to-windows" class="sidebar-link">Quick Start to Windows</a></li><li class="sidebar-sub-header"><a href="/openncc/3_GettingStart.html#quick-start-to-raspberry-pi" class="sidebar-link">Quick Start to Raspberry Pi</a></li><li class="sidebar-sub-header"><a href="/openncc/3_GettingStart.html#custom-customization" class="sidebar-link">Custom（Customization）</a></li><li class="sidebar-sub-header"><a href="/openncc/3_GettingStart.html#running-result" class="sidebar-link">Running result</a></li></ul></li><li><a href="/openncc/4_nccview.html" class="sidebar-link">OpenNCC View's Manual</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/openncc/4_nccview.html#overview" class="sidebar-link">Overview</a></li><li class="sidebar-sub-header"><a href="/openncc/4_nccview.html#model-analysis" class="sidebar-link">Model analysis</a></li><li class="sidebar-sub-header"><a href="/openncc/4_nccview.html#functions-detail" class="sidebar-link">Functions detail</a></li><li class="sidebar-sub-header"><a href="/openncc/4_nccview.html#algorithms-speed-up-test-results" class="sidebar-link">Algorithms speed up test results</a></li></ul></li><li><a href="/openncc/5_Software_Manual.html" aria-current="page" class="active sidebar-link">Software User's Manual</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/openncc/5_Software_Manual.html#overview" class="sidebar-link">Overview</a></li><li class="sidebar-sub-header"><a href="/openncc/5_Software_Manual.html#sdk-structure" class="sidebar-link">SDK structure</a></li><li class="sidebar-sub-header"><a href="/openncc/5_Software_Manual.html#supported-platform" class="sidebar-link">Supported platform</a></li><li class="sidebar-sub-header"><a href="/openncc/5_Software_Manual.html#openvino-installation-and-getting-start" class="sidebar-link">OpenVINO installation and getting start</a></li><li class="sidebar-sub-header"><a href="/openncc/5_Software_Manual.html#openncc-operating-mechanism" class="sidebar-link">OpenNCC operating mechanism</a></li></ul></li><li><a href="/openncc/6_Openncc_sdk_api.html" class="sidebar-link">SDK API</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/openncc/6_Openncc_sdk_api.html#openncc-sdk-api-3-0-x-interface-documentation" class="sidebar-link">OpenNCC SDK API 3.0.x Interface Documentation</a></li></ul></li><li><a href="/openncc/7_openvino_install.html" class="sidebar-link">How to install OpenVINO</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/openncc/7_openvino_install.html#download-and-install-openvino" class="sidebar-link">Download and Install OpenVINO</a></li></ul></li><li><a href="/openncc/8_DownloadLink.html" class="sidebar-link">Download Released Packets</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/openncc/8_DownloadLink.html#download-links" class="sidebar-link">Download Links</a></li></ul></li><li><a href="/openncc/9_FAQ.html" class="sidebar-link">FAQ</a><ul class="sidebar-sub-headers"></ul></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h2 id="overview"><a href="#overview" class="header-anchor">#</a> Overview</h2> <p>This chapter introduces the SDK which contains the library of resources necessary for the application and the related basic application routines.</p> <h2 id="sdk-structure"><a href="#sdk-structure" class="header-anchor">#</a> SDK structure</h2> <table><thead><tr><th>Directory</th> <th>Content</th></tr></thead> <tbody><tr><td>./Platform</td> <td>Contains  scripts for generating runtime environments for different platforms.</td></tr> <tr><td>./SDK/docs</td> <td>Contains  SDK-related introduction and documentation.</td></tr> <tr><td>./SDK/Drivers</td> <td>Contains  the drivers that must be installed for different platforms.</td></tr> <tr><td>./SDK/Example</td> <td>Contains  SDK related routines.</td></tr> <tr><td>./SDK/Source</td> <td>Includes  firmware, model and SDK library files.</td></tr> <tr><td>./SDK/Tools</td> <td>Includes  relevant model conversion and compilation tools.</td></tr> <tr><td>./Viewer</td> <td>Includes  compiled Viewer and QT source code.</td></tr></tbody></table> <h2 id="supported-platform"><a href="#supported-platform" class="header-anchor">#</a> Supported platform</h2> <p>SDK支持的产品如下：</p> <ul><li><p>OpenNCC DK</p></li> <li><p>OpenNCC Lite</p></li> <li><p>OpenNCC USB</p></li></ul> <p>SDK支持的平台如下：</p> <ul><li>Ubuntu 16.04, Ubuntu 18.04</li> <li>Windows 10</li> <li>Raspberry Pi</li> <li>Arm Linux</li></ul> <p>SDK支持的语言如下：</p> <ul><li>C/C++</li> <li>Python3.5、Python3.7</li></ul> <h3 id="sdk-development-package-directory-structure"><a href="#sdk-development-package-directory-structure" class="header-anchor">#</a> SDK development package directory structure</h3> <table><thead><tr><th>Directory</th> <th>Contents</th></tr></thead> <tbody><tr><td>Example/How_to/How_to_use_sdk</td> <td>Sample  application, how to use the SDK library in your project.</td></tr> <tr><td>Example/How_to/Capture_video</td> <td>Sample  application, how to get a video stream using the SDK library.</td></tr> <tr><td>Example/How_to/Load_a_model</td> <td>Sample  application, how to download a deep learning model in Blob format using the  SDK library.</td></tr> <tr><td>Example/How_to/work_with_multiple_models</td> <td>Sample  application, how to use a second-level model.</td></tr> <tr><td>Example/How_to/Python_demo</td> <td>Python  related examples.</td></tr> <tr><td>Example/Linkage_demo/  <br>work with AlwaysAI /  <br>pedestrian_tracking_demo</td> <td>Face  model, using AlwaysAI to parse the result display and count the number of  people passing the recognition area.</td></tr> <tr><td>Example/Linkage_demo/  <br>work_with_OpenVINO/  <br>human_pose_estimation_demo</td> <td>Human  skeleton model, using OpenVINO to parse the result display.</td></tr> <tr><td>Example/Linkage_demo/  <br>work_with_OpenVINO/  <br>interactive_face_detection_demo</td> <td>Face,  age, gender, and mood models, using OpenVINO parsing results.</td></tr> <tr><td>Example/Linkage_demo/  <br>work_with_PaddlePaddle</td> <td>OCR Sample application, include a network link to the OCR warehouse.</td></tr> <tr><td>Tools/myriad_compiler</td> <td>IR file conversion Blob file tool</td></tr> <tr><td>Tools/deployment</td> <td>Kit deployment script</td></tr></tbody></table> <h2 id="openvino-installation-and-getting-start"><a href="#openvino-installation-and-getting-start" class="header-anchor">#</a> OpenVINO installation and getting start</h2> <p>   To deploy a deep learning model on end-point target devices, you need to optimize and convert a trained model to the VPU characteristics to achieve higher operating performance. OpenNCC is compatible with OpenVINO's tool set and model format, and needs to rely on Intel OpenVINO's model optimizer to complete model optimization and conversion into Blob format. When using OpenNCC SDK, you need to install OpenVINO as follows:
If you need to convert the trained model yourself, you need to install OpenVINO to run the model optimizer.
When OpenVINO runs in a mixed mode with the OpenVINO inference engine, it also needs OpenVINO support.</p> <h3 id="download-and-install-openvino"><a href="#download-and-install-openvino" class="header-anchor">#</a> Download and install OpenVINO</h3> <p>  OpenNCC currently supports OpenVINO version: 2020.3.194, OpenVINO installation reference <a href="/openncc/openvino_install.html">here</a></p> <h3 id="intel-free-model-download"><a href="#intel-free-model-download" class="header-anchor">#</a> Intel Free model download</h3> <p>  OpenNCC supports OpenVINO models, Intel has a large number of free trained models for learning reference and testing. After we have installed OpenVINO, we can use the Intel download tool to download the model collection. Model download tool path: <code>openvino/deployment_tools/tools/model_downloader/downloader.py</code>, common commands are as follows:</p> <ul><li>View all downloadable models：./downloader.py --print</li> <li>Download the specified model：./downloader.py --name *</li></ul> <p>For example, download a face detection model ：<code>./downloader.py --name face-detection-adas-0001-fp16</code><br> <img src="/openncc/docimg/sw_figure1.png" alt="Figure-1"></p> <h3 id="model-optimization-and-format-conversion"><a href="#model-optimization-and-format-conversion" class="header-anchor">#</a> Model optimization and format conversion</h3> <p> When we need to deploy a trained model to OpenNCC, we need to optimize and transform the model. After installing OpenVINO, you can use the model optimization tool: <code>/opt/intel/openvino/deployment_tools/model_optimizer/mo.py</code> to optimize the model. For specific documents, see the official Intel documents: <a href="https://docs.openvinotoolkit.org/2020.3/_docs_MO_DG_prepare_model_Config_Model_Optimizer.html" target="_blank" rel="noopener noreferrer">Model Optimizer Developer Guide<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p> After the model optimization is completed, the model needs to be converted to the Blob format before it can be deployed on OpenNCC. In the OpenVINO installation directory: <code>/opt/intel/openvino/deployment_tools/inference_engine/lib/intel64myriad_compile</code> tool, the method of use is as follows:
Enter from the command line terminal：<code>./myriad_compile -m input_xxx-fp16.xml  -o output_xxx.blob  -VPU_PLATFORM VPU_2480 -VPU_NUMBER_OF_SHAVES  8  -VPU_NUMBER_OF_CMX_SLICES 8</code></p> <p>  After the format conversion is completed, the model can be deployed on OpenNCC, refer to: <code>ncc_SDK/Samples/How_to/load a model</code>, or use the OpenNCC View interface program to add the model to deploy and test it.</p> <h2 id="openncc-operating-mechanism"><a href="#openncc-operating-mechanism" class="header-anchor">#</a> OpenNCC operating mechanism</h2> <p>  From a model training environment to embedded deployment, it is a very important task, which requires mastering the framework of deep learning, such as commonly used: Caffe*, TensorFlow*, MXNet*, Kaldi*, etc.In addition, it is very important to master the deployed embedded platform. You need to understand the platform performance, system architecture characteristics, and then combine the platform characteristics to optimize the training model framework, and finally tune, transplant, and deploy to the embedded platform.</p> <p>  OpenNCC focuses on the rapid deployment of deep learning models, is compatible with Intel OpenVINO tools, and for embedded graphics and image application scenarios, it has completed the integration of different resolution sensors from 2MP to 20MP on end-point target devices, and the end-point target devices has realized the deployment of professional-level ISP.  OpenVINO optimized converted model files can be dynamically downloaded to the end-point OpenNCC camera to achieve rapid deployment of deep learning models. OpenNCC has designed independent working mode, mixed development mode and co-processing compute stick mode to adapt to different work application scenarios.</p> <h3 id="openncc-standalone-mode"><a href="#openncc-standalone-mode" class="header-anchor">#</a> OpenNCC standalone mode</h3> <p> In the independent mode, OpenNCC independently runs a deep learning model, and feeds back the inference results to the user through the OpenNCC SDK API.
The application deployment process is as follows:</p> <p><img src="/openncc/docimg/sw_figure2.png" alt="Figure-2"></p> <p> According to the OpenVINO documentation, for a specific training framework <a href="https://docs.openvinotoolkit.org/2020.3/_docs_MO_DG_prepare_model_Config_Model_Optimizer.html" target="_blank" rel="noopener noreferrer">Configure Model Optimizer<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p> Run <a href="https://docs.openvinotoolkit.org/2020.3/_docs_IE_DG_Introduction.html#MO" target="_blank" rel="noopener noreferrer">Model Optimizer<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> to produce an optimized Intermediate Representation (IR) of the model based on the trained network topology, weights and biases values, and other optional parameters.
The IR is a pair of files that describe the whole model:</p> <ul><li>.xml: The topology file - an XML file that describes the network topology</li> <li>.bin: The trained data file - a .bin file that contains the weights and biases binary data</li> <li>Then run myriad_compile to generate a BLOB file from the IR file.</li> <li>To integrate the BLOB model file generated after optimization using OpenNCC SDK, see the demo program of <code>Examples/How_to/Load a model</code> under SDK.</li> <li>  OpenNCC View is an application demonstration program with an operating interface integrated with OpenNCC SDK. You can also use OpenView to deploy models and obtain test results. Refer to OpenNCC View Guide Because different depth models have differentiated inference output results, if users cannot find a suitable post-processing analytical model under the SDK, they need to refer to <code>Examples/How_to/load a model</code> and write post-processing code in combination with their own application scenarios.</li></ul> <h4 id="secondary-model-operation-support"><a href="#secondary-model-operation-support" class="header-anchor">#</a> Secondary model operation support</h4> <p>Considering the end-to-side computing capability, at present, SDK multi-level models support cascading of two-level models, as shown in the following figure:</p> <p><img src="/openncc/docimg/ch/SoftManualF10.jpg" alt="F"></p> <p>The first level model must be a target detection or classification model, and the output is defined as follows:</p> <p><img src="/openncc/docimg/ch/SoftManualF11.jpg" alt="F"></p> <p>process：</p> <p>1）After pre CV [1], the original image scale is converted to the input size of the first level model, and the corresponding format conversion is performed. Then the first level model reasoning calculation is performed, and the first level reasoning result is output to pre CV [2].</p> <ol start="2"><li>The pre CV [2] module analyzes the reasoning results of the first level model, and takes the qualified label and conf detection target according to the coordinate starting point (x)_ min, y_ Min), the end point (x)_ max,y_ Max) from the original graph's Cross and scale are converted to the input size of the secondary model, and the corresponding format conversion is performed to enter the second level model reasoning.</li></ol> <p>3）Finally, the reasoning results of the first level model and all the second level models are packaged and output together.</p> <p>Model output analysis (parameter configuration in the figure is: valid label: 2,3, conf = 0.8)</p> <p><img src="/openncc/docimg/ch/SoftManualF12.png" alt="F"></p> <p>Example：<code>Examples/How_to/work_with_multiple_models</code>,the first level model is vehicle and license plate detection, the second level model is license plate detection, and the effective label is set to 2</p> <p>Based on the detection results of the first stage, the detection coordinates of the first stage are adjusted appropriately, which is conducive to the identification of:</p> <p>*Fine tuning the starting point to the left and up（startXAdj，startYAdj ）</p> <p>*Bottom right down fine adjustment（endXAdj，endYAdj）</p> <p>cnn2PrmSet.startXAdj  = -5;</p> <p>cnn2PrmSet.startYAdj  = -5;</p> <p>cnn2PrmSet.endXAdj   = 5;</p> <p>cnn2PrmSet.endYAdj   = 5;</p> <h3 id="openncc-mixed-mode"><a href="#openncc-mixed-mode" class="header-anchor">#</a> OpenNCC mixed mode</h3> <p> When it is necessary to solve some complex application scenarios, multiple network model combination processing is required, OpenNCC end-point computing performance cannot be met, or the end-side processing needs to be concentrated on the edge side for post-processing, system expansion is often required. Run the models with high real-time requirements on the OpenNCC end-point, and the other models on the post-processing edge machine or cloud.</p> <p> As shown in the figure, Model-1 runs on the OpenNCC end-point  to complete the pre-processing of the video stream. OpenNNC returns the results of the first-level processing model to the user application. Model-1 and Model-2 fully run under the OpenVINO inference engine to implement subsequent processing.</p> <p><img src="/openncc/docimg/sw_figure3.png" alt="Figure-3"></p> <p> In <code>Examples/Linkage_demo/work_with_OpenVINO</code> demonstrated how to combine OpenNCC and OpenVINO on Host PC to implement a distributed AI system.</p> <h3 id="co-processing-compute-stick-mode"><a href="#co-processing-compute-stick-mode" class="header-anchor">#</a> Co-processing compute stick mode</h3> <p> OpenNCC's co-processing mode is similar to Intel NCS2. In this mode of operation, OpenNCC's vision sensor does not work, and users can use OpenNCC alone to achieve full compatibility with the OpenVINO environment. The typical deep learning model deployment process of OpenVINO is as follows:</p> <p><img src="/openncc/docimg/sw_figure4.png" alt="Figure-4"></p> <p><a href="https://docs.openvinotoolkit.org/2020.3/_docs_MO_DG_prepare_model_Config_Model_Optimizer.html" target="_blank" rel="noopener noreferrer">Configure Model Optimizer<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> for specific training framework according to OpenVINO documentation.</p> <p> Run Model Optimizer to produce an optimized Intermediate Representation (IR) of the model based on the trained network topology, weights and biases values, and other optional parameters.</p> <p> Download the optimized IR file to OpenNCC to run the Inference Engine. For details, refer to OpenVINO documents: <a href="https://docs.openvinotoolkit.org/2020.3/_docs_IE_DG_Introduction.html#IE" target="_blank" rel="noopener noreferrer">Inference Engine validation application<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> and <a href="https://docs.openvinotoolkit.org/2019_R1.1/_docs_IE_DG_Samples_Overview.html" target="_blank" rel="noopener noreferrer">sample applications.<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p> Copy <code>Source/Firmware/fw /usb-ma2x8x.mvcmd</code> and replace openvino/inference_engine/lib/intel64/usb-ma2x8x.mvcmd in the openvino installation directory.(Remarks: usb-ma2x8x.mvcmd in the openvino installation directory must be backed up before replacement. This file needs to be restored when using NCS2 inference)</p> <h3 id="difference-between-independent-mode-and-co-processing-mode"><a href="#difference-between-independent-mode-and-co-processing-mode" class="header-anchor">#</a> Difference between independent mode and co-processing mode</h3> <p> The right side of the figure below is the independent mode of OpenNCC, and the left side is the co-processing mode of OpenNCC (similar to Intel NCS2).</p> <p><img src="/openncc/docimg/sw_figure5.png" alt="Figure-5"></p> <p> When we need to deploy a vision-based deep learning model, first we need to obtain a high-quality video stream, then run the inference engine to calculate the input image data, and finally output the result. For the co-processing mode on the left, we need an OpenNCC or Intel NCS2 implements end-to-side reasoning. At the same time, we need to obtain a video stream from a camera and send the video frame to OpenNCC  via USB. In the independent mode on the right, no additional camera is needed to obtain the video stream. We only need to download the model to OpenNCC to obtain the deduction results.</p> <p>Refer to OpenVINO official website:https://docs.openvinotoolkit.org/</p></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/openncc/4_nccview.html" class="prev">
        OpenNCC View's Manual
      </a></span> <span class="next"><a href="/openncc/6_Openncc_sdk_api.html">
        SDK API
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/openncc/assets/js/app.92ec51d4.js" defer></script><script src="/openncc/assets/js/2.bef35a51.js" defer></script><script src="/openncc/assets/js/11.057199e2.js" defer></script>
  </body>
</html>
