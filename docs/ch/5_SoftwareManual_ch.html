<!DOCTYPE html>
<html lang="中文">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>概述 | OpenNCC技术文档</title>
    <meta name="generator" content="VuePress 1.8.2">
    
    <meta name="description" content="开放人工智能摄像机">
    
    <link rel="preload" href="/openncc/assets/css/0.styles.a0bcdeaa.css" as="style"><link rel="preload" href="/openncc/assets/js/app.92ec51d4.js" as="script"><link rel="preload" href="/openncc/assets/js/2.bef35a51.js" as="script"><link rel="preload" href="/openncc/assets/js/21.0fb2149e.js" as="script"><link rel="prefetch" href="/openncc/assets/js/10.476ef782.js"><link rel="prefetch" href="/openncc/assets/js/11.057199e2.js"><link rel="prefetch" href="/openncc/assets/js/12.ba397f51.js"><link rel="prefetch" href="/openncc/assets/js/13.f6f26a71.js"><link rel="prefetch" href="/openncc/assets/js/14.aa0cf5bd.js"><link rel="prefetch" href="/openncc/assets/js/15.f7699c14.js"><link rel="prefetch" href="/openncc/assets/js/16.e9b2b8ce.js"><link rel="prefetch" href="/openncc/assets/js/17.ab6a5284.js"><link rel="prefetch" href="/openncc/assets/js/18.6bd5b3ac.js"><link rel="prefetch" href="/openncc/assets/js/19.6a4f8811.js"><link rel="prefetch" href="/openncc/assets/js/20.98eb93f3.js"><link rel="prefetch" href="/openncc/assets/js/22.601d034a.js"><link rel="prefetch" href="/openncc/assets/js/23.e4e6a9a3.js"><link rel="prefetch" href="/openncc/assets/js/24.b6ea03d5.js"><link rel="prefetch" href="/openncc/assets/js/25.e889ad31.js"><link rel="prefetch" href="/openncc/assets/js/26.ad699543.js"><link rel="prefetch" href="/openncc/assets/js/27.8e57c10f.js"><link rel="prefetch" href="/openncc/assets/js/28.ad251330.js"><link rel="prefetch" href="/openncc/assets/js/29.d2238b47.js"><link rel="prefetch" href="/openncc/assets/js/3.33041445.js"><link rel="prefetch" href="/openncc/assets/js/30.05b368dd.js"><link rel="prefetch" href="/openncc/assets/js/4.e7c996f5.js"><link rel="prefetch" href="/openncc/assets/js/5.6eff8140.js"><link rel="prefetch" href="/openncc/assets/js/6.17d5dd20.js"><link rel="prefetch" href="/openncc/assets/js/7.51eccf5b.js"><link rel="prefetch" href="/openncc/assets/js/8.4fe559b3.js"><link rel="prefetch" href="/openncc/assets/js/9.edef11f0.js">
    <link rel="stylesheet" href="/openncc/assets/css/0.styles.a0bcdeaa.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/openncc/ch/" class="home-link router-link-active"><!----> <span class="site-name">OpenNCC技术文档</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="https://www.openncc.com.cn" target="_blank" rel="noopener noreferrer" class="nav-link external">
  OpenNCC
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="https://gitee.com/eyecloud/openncc" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Gitee
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="https://docs.openvinotoolkit.org/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  OpenVINO
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Select language" class="dropdown-title"><span class="title">Languages</span> <span class="arrow down"></span></button> <button type="button" aria-label="Select language" class="mobile-dropdown-title"><span class="title">Languages</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/openncc/" class="nav-link">
  English
</a></li><li class="dropdown-item"><!----> <a href="/openncc/ch/5_SoftwareManual_ch.html" aria-current="page" class="nav-link router-link-exact-active router-link-active">
  中文
</a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="https://www.openncc.com.cn" target="_blank" rel="noopener noreferrer" class="nav-link external">
  OpenNCC
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="https://gitee.com/eyecloud/openncc" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Gitee
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="https://docs.openvinotoolkit.org/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  OpenVINO
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Select language" class="dropdown-title"><span class="title">Languages</span> <span class="arrow down"></span></button> <button type="button" aria-label="Select language" class="mobile-dropdown-title"><span class="title">Languages</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/openncc/" class="nav-link">
  English
</a></li><li class="dropdown-item"><!----> <a href="/openncc/ch/5_SoftwareManual_ch.html" aria-current="page" class="nav-link router-link-exact-active router-link-active">
  中文
</a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><a href="/openncc/ch/1_Introduction_ch.html" class="sidebar-link">OpenNCC介绍</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/openncc/ch/1_Introduction_ch.html#openncc-概述" class="sidebar-link">OpenNCC 概述</a></li><li class="sidebar-sub-header"><a href="/openncc/ch/1_Introduction_ch.html#openncc-功能介绍" class="sidebar-link">OpenNCC 功能介绍</a></li><li class="sidebar-sub-header"><a href="/openncc/ch/1_Introduction_ch.html#openncc系列产品" class="sidebar-link">OpenNCC系列产品</a></li></ul></li><li><a href="/openncc/ch/2_HardwareManual_ch.html" class="sidebar-link">OpenNCC 硬件手册</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/openncc/ch/2_HardwareManual_ch.html#硬件规格" class="sidebar-link">硬件规格</a></li><li class="sidebar-sub-header"><a href="/openncc/ch/2_HardwareManual_ch.html#开箱展示" class="sidebar-link">开箱展示</a></li><li class="sidebar-sub-header"><a href="/openncc/ch/2_HardwareManual_ch.html#硬件启动" class="sidebar-link">硬件启动</a></li></ul></li><li><a href="/openncc/ch/3_GettingStart_ch.html" class="sidebar-link">OpenNCC 快速开始</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/openncc/ch/3_GettingStart_ch.html#准备工作" class="sidebar-link">准备工作</a></li><li class="sidebar-sub-header"><a href="/openncc/ch/3_GettingStart_ch.html#快速入门之linux" class="sidebar-link">快速入门之linux</a></li><li class="sidebar-sub-header"><a href="/openncc/ch/3_GettingStart_ch.html#快速入门之windows" class="sidebar-link">快速入门之Windows</a></li><li class="sidebar-sub-header"><a href="/openncc/ch/3_GettingStart_ch.html#快速入门之raspberry-pi" class="sidebar-link">快速入门之Raspberry Pi</a></li><li class="sidebar-sub-header"><a href="/openncc/ch/3_GettingStart_ch.html#custom-自定义" class="sidebar-link">Custom（自定义）</a></li><li class="sidebar-sub-header"><a href="/openncc/ch/3_GettingStart_ch.html#运行结果演示" class="sidebar-link">运行结果演示</a></li></ul></li><li><a href="/openncc/ch/4_NccView_ch.html" class="sidebar-link">OpenNCC View说明</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/openncc/ch/4_NccView_ch.html#概述" class="sidebar-link">概述</a></li><li class="sidebar-sub-header"><a href="/openncc/ch/4_NccView_ch.html#模型解析" class="sidebar-link">模型解析</a></li><li class="sidebar-sub-header"><a href="/openncc/ch/4_NccView_ch.html#功能点详细介绍" class="sidebar-link">功能点详细介绍</a></li><li class="sidebar-sub-header"><a href="/openncc/ch/4_NccView_ch.html#算法加速功能介绍" class="sidebar-link">算法加速功能介绍</a></li></ul></li><li><a href="/openncc/ch/5_SoftwareManual_ch.html" aria-current="page" class="active sidebar-link">软件开发包手册</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/openncc/ch/5_SoftwareManual_ch.html#概述" class="sidebar-link">概述</a></li><li class="sidebar-sub-header"><a href="/openncc/ch/5_SoftwareManual_ch.html#sdk结构" class="sidebar-link">SDK结构</a></li><li class="sidebar-sub-header"><a href="/openncc/ch/5_SoftwareManual_ch.html#支持的产品及平台" class="sidebar-link">支持的产品及平台</a></li><li class="sidebar-sub-header"><a href="/openncc/ch/5_SoftwareManual_ch.html#已集成的ai模型" class="sidebar-link">已集成的AI模型</a></li><li class="sidebar-sub-header"><a href="/openncc/ch/5_SoftwareManual_ch.html#openvino-安装和使用" class="sidebar-link">OpenVINO 安装和使用</a></li><li class="sidebar-sub-header"><a href="/openncc/ch/5_SoftwareManual_ch.html#openncc运行机制" class="sidebar-link">OpenNCC运行机制</a></li></ul></li><li><a href="/openncc/ch/6_SdkApi_ch.html" class="sidebar-link">OpenNCC SDK接口文档</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/openncc/ch/6_SdkApi_ch.html#openncc-sdk-api-3-0-x接口文档" class="sidebar-link">OpenNCC SDK API 3.0.x接口文档</a></li></ul></li><li><a href="/openncc/ch/7_OpenvinoInstall_ch.html" class="sidebar-link">OpenVINO安装说明</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/openncc/ch/7_OpenvinoInstall_ch.html#openvino安装指南" class="sidebar-link">OpenVINO安装指南</a></li></ul></li><li><a href="/openncc/ch/8_DownloadLink_ch.html" class="sidebar-link">安装包和源码下载地址</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/openncc/ch/8_DownloadLink_ch.html#下载地址" class="sidebar-link">下载地址</a></li></ul></li><li><a href="/openncc/ch/9_FAQ_ch.html" class="sidebar-link">常见问题</a><ul class="sidebar-sub-headers"></ul></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h2 id="概述"><a href="#概述" class="header-anchor">#</a> 概述</h2> <p> 该文档用于介绍OpenNCC Software Development Kit (SDK) 并且包含了启动，运行及开发的所有必要信息。</p> <h2 id="sdk结构"><a href="#sdk结构" class="header-anchor">#</a> SDK结构</h2> <table><thead><tr><th>目录</th> <th>内容</th></tr></thead> <tbody><tr><td>./Platform</td> <td>包含不同平台生成运行环境的脚本。</td></tr> <tr><td>./SDK/docs</td> <td>包含SDK相关介绍和文档。</td></tr> <tr><td>./SDK/Drivers</td> <td>包含不同平台所必须安装的驱动。</td></tr> <tr><td>./SDK/Example</td> <td>包含SDK的相关例程。</td></tr> <tr><td>./SDK/Source</td> <td>包含固件，模型及SDK库文件。</td></tr> <tr><td>./SDK/Tools</td> <td>包含相关的模型转换及编译工具。</td></tr> <tr><td>./Viewer</td> <td>包含已编译的Viewer及QT源码。</td></tr></tbody></table> <h2 id="支持的产品及平台"><a href="#支持的产品及平台" class="header-anchor">#</a> 支持的产品及平台</h2> <p>SDK支持的产品如下：</p> <ul><li><p>OpenNCC DK</p></li> <li><p>OpenNCC Lite</p></li> <li><p>OpenNCC USB</p></li></ul> <p>SDK支持的平台如下：</p> <ul><li>Ubuntu 16.04, Ubuntu 18.04</li> <li>Windows 10</li> <li>Raspberry Pi（树莓派）</li> <li>Arm Linux(需提供工具链交叉编译)</li></ul> <p>SDK支持的语言如下：</p> <ul><li>C/C++</li> <li>Python3.5、Python3.7</li></ul> <h3 id="sdk开发包目录结构"><a href="#sdk开发包目录结构" class="header-anchor">#</a> SDK开发包目录结构</h3> <table><thead><tr><th>目录</th> <th style="text-align:left;">内容概要</th></tr></thead> <tbody><tr><td>Example/How_to<br>/How_to_use_sdk</td> <td style="text-align:left;">示例程序，如何在项目中使用SDK库。</td></tr> <tr><td>Example/How_to<br>/Capture_video</td> <td style="text-align:left;">示例程序，使用SDK库获取视频流。</td></tr> <tr><td>Example/How_to<br>/Load_a_model</td> <td style="text-align:left;">示例程序，使用SDK库下载一个Blob格式的深度学习模型。</td></tr> <tr><td>Example/How_to<br>/work_with_multiple_models</td> <td style="text-align:left;">示例程序，二级模型的应用。</td></tr> <tr><td>Example/How_to<br>/Python_demo</td> <td style="text-align:left;">Python的相关示例。</td></tr> <tr><td>Example/Linkage_demo<br>/work with AlwaysAI <br>/pedestrian_tracking_demo</td> <td style="text-align:left;">人脸模型，使用AlwaysAI解析结果显示，并统计通过识别区域的人数。</td></tr> <tr><td>Example/Linkage_demo<br>/work_with_OpenVINO<br>/human_pose_estimation_demo</td> <td style="text-align:left;">人体骨骼模型，使用OpenVINO解析结果显示。</td></tr> <tr><td>Example/Linkage_demo<br>/work_with_OpenVINO<br>/interactive_face_detection_demo</td> <td style="text-align:left;">人脸、年龄、性别、心情模型，使用OpenVINO解析结果显示。</td></tr> <tr><td>Example/Linkage_demo<br>/work_with_PaddlePaddle</td> <td style="text-align:left;">OCR文字识别示例程序，包含OpenNCC PaddlePaddle-OCR 仓库链接。</td></tr> <tr><td>Tools/myriad_compiler</td> <td style="text-align:left;">IR文件转换成Blob文件工具</td></tr> <tr><td>Tools/deployment</td> <td style="text-align:left;">权限部署脚本</td></tr></tbody></table> <h2 id="已集成的ai模型"><a href="#已集成的ai模型" class="header-anchor">#</a> 已集成的AI模型</h2> <table><thead><tr><th>模型类别</th> <th>名称</th> <th>简介</th> <th>其他参考</th></tr></thead> <tbody><tr><td>物体分类</td> <td>classification-fp16</td> <td>ssd_mobilenet_v1_coco model can detect almost 90 objects</td> <td><a href="https://docs.openvinotoolkit.org/latest/omz_models_public_ssd_mobilenet_v1_coco_ssd_mobilenet_v1_coco.html" target="_blank" rel="noopener noreferrer">OpenVINO Doc Link<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></td></tr> <tr><td>人脸、人形检测</td> <td>face-detection-adas-0001-fp16</td> <td>Face detector for driver monitoring and similar scenarios. The network features a default MobileNet backbone that includes depth-wise convolutions to reduce the amount of computation for the 3x3 convolution block</td> <td><a href="http://docs.openvinotoolkit.org/2019_R1.1/_face_detection_adas_0001_description_face_detection_adas_0001.html" target="_blank" rel="noopener noreferrer">OpenVINO Doc Link<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></td></tr> <tr><td></td> <td>face-detection-retail-0004-fp16</td> <td>Face detector based on SqueezeNet light (half-channels) as a backbone with a single SSD for indoor/outdoor scenes shot by a front-facing camera</td> <td><a href="https://docs.openvinotoolkit.org/2019_R1.1/_face_detection_retail_0004_description_face_detection_retail_0004.html" target="_blank" rel="noopener noreferrer">OpenVINO Doc Link<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></td></tr> <tr><td></td> <td>face-person-detection-retail-0002-fp16</td> <td>This is a pedestrian detector based on backbone with hyper-feature + R-FCN for the Retail scenario</td> <td><a href="https://docs.openvinotoolkit.org/2019_R1.1/person-detection-retail-0002.html" target="_blank" rel="noopener noreferrer">OpenVINO Doc Link<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></td></tr> <tr><td></td> <td>person-detection-retail-0013-fp16</td> <td>This is a pedestrian detector for the Retail scenario. It is based on MobileNetV2-like backbone that includes depth-wise convolutions to reduce the amount of computation for the 3x3 convolution block</td> <td><a href="https://docs.openvinotoolkit.org/2019_R1.1/_person_detection_retail_0013_description_person_detection_retail_0013.html" target="_blank" rel="noopener noreferrer">OpenVINO Doc Link<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></td></tr> <tr><td></td> <td>pedestrian-detection-adas-0002-fp16</td> <td>Pedestrian detection network based on SSD framework with tuned MobileNet v1 as a feature extractor.</td> <td><a href="https://docs.openvinotoolkit.org/2019_R1.1/_pedestrian_detection_adas_0002_description_pedestrian_detection_adas_0002.html" target="_blank" rel="noopener noreferrer">OpenVINO Doc Link<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></td></tr> <tr><td>人车、自行车</td> <td>person-vehicle-bike-detection-crossroad-0078-fp16</td> <td>Person/Vehicle/Bike detector is based on SSD detection architecture, RMNet backbone, and learnable image downscale block (like person-vehicle-bike-detection-crossroad-0066, but with extra pooling)</td> <td><a href="https://docs.openvinotoolkit.org/2019_R1.1/_person_vehicle_bike_detection_crossroad_0078_description_person_vehicle_bike_detection_crossroad_0078.html" target="_blank" rel="noopener noreferrer">OpenVINO Doc Link<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></td></tr> <tr><td></td> <td>pedestrian-and-vehicle-detector-adas-0001-fp16</td> <td>Pedestrian and vehicle detection network based on MobileNet v1.0 + SSD.</td> <td><a href="https://docs.openvinotoolkit.org/2019_R1.1/_pedestrian_and_vehicle_detector_adas_0001_description_pedestrian_and_vehicle_detector_adas_0001.html" target="_blank" rel="noopener noreferrer">OpenVINO Doc Link<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></td></tr> <tr><td>车辆检测</td> <td>vehicle-detection-adas-0002-fp16</td> <td>This is a vehicle detection network based on an SSD framework with tuned MobileNet v1 as a feature extractor.</td> <td><a href="http://docs.openvinotoolkit.org/2019_R1.1/_vehicle_detection_adas_0002_description_vehicle_detection_adas_0002.html" target="_blank" rel="noopener noreferrer">OpenVINO Doc Link<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></td></tr> <tr><td>口罩检测</td> <td>Mask-detect-fp16</td> <td>Mask detect</td> <td>Under license</td></tr> <tr><td>车牌识别</td> <td>vehicle-license-plate-detection-barrier-0106-fp16</td> <td>This is a MobileNetV2 + SSD-based vehicle and (Chinese) license plate detector for the &quot;Barrier&quot; use case.</td> <td><a href="https://docs.openvinotoolkit.org/2019_R1.1/_vehicle_license_plate_detection_barrier_0106_description_vehicle_license_plate_detection_barrier_0106.html" target="_blank" rel="noopener noreferrer">OpenVINO Doc Link<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></td></tr> <tr><td>人脸属性</td> <td>interactive_face_detection_demo</td> <td>This demo executes four parallel infer requests for the Age/Gender Recognition, Head Pose Estimation, Emotions Recognition, and Facial Landmarks Detection networks that run simultaneously</td> <td><a href="https://docs.openvinotoolkit.org/2019_R1.1/_inference_engine_samples_interactive_face_detection_demo_README.html" target="_blank" rel="noopener noreferrer">OpenVINO Doc Link<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></td></tr> <tr><td>人体骨骼提取</td> <td>human-pose-estimation-0001-fp16</td> <td>A multi-person 2D pose estimation network (based on the OpenPose approach) with tuned MobileNet v1 as a feature extractor.</td> <td><a href="https://docs.openvinotoolkit.org/2019_R1.1/_human_pose_estimation_0001_description_human_pose_estimation_0001.html" target="_blank" rel="noopener noreferrer">OpenVINO Doc Link<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></td></tr></tbody></table> <h2 id="openvino-安装和使用"><a href="#openvino-安装和使用" class="header-anchor">#</a> OpenVINO 安装和使用</h2> <p> 在端侧部署一个深度学习模型，需要将一个训练完成的模型经过针对VPU特性的模型优化和转换，以达到较高的运行性能。OpenNCC兼容OpenVINO的工具集和模型格式，需要依赖Intel OpenVINO的模型优化器来完成模型优化和转换成Blob格式。使用OpenNCC SDK时需要安装OpenVINO的两种情况如下：</p> <div class="language- extra-class"><pre><code>如果需要自行转换训练好的模型，那么需要安装OpenVINO，来运行模型优化器。
当OpenVINO运行在与OpenVINO推理引擎的混合模式时，也需要OpenVINO支持。
</code></pre></div><h3 id="下载并安装openvino"><a href="#下载并安装openvino" class="header-anchor">#</a> 下载并安装OpenVINO</h3> <p> OpenNCC 目前支持OpenVINO版本：2020.3.194,<a href="/openncc/ch/7_OpenvinoInstall_ch.html">OpenVINO安装教程</a></p> <h3 id="intel-free模型下载"><a href="#intel-free模型下载" class="header-anchor">#</a> Intel Free模型下载</h3> <p> OpenNCC支持OpenVINO下生产的模型，Intel有大量免费训练好的模型供学习参考和评测。当我们安装完成OpenVINO后，可以使用Intel下载工具下载模型集合。模型下载工具路径：openvino/deployment_tools/tools/model_downloader/downloader.py ,常用命令如下：</p> <p>查看全部可下载的模型：<code>./downloader.py --print</code></p> <p>下载指定的模型：<code>./downloader.py --name *</code></p> <p>例如下载一个人脸检测模型 ：<code>./downloader.py --name face-detection-adas-0001-fp16</code></p> <p><img src="/openncc/docimg/ch/SoftManualF1.png" alt="F1"></p> <h3 id="模型的优化和格式转换"><a href="#模型的优化和格式转换" class="header-anchor">#</a> 模型的优化和格式转换</h3> <p> 当我们需要将一个训练好模型部署到OpenNCC时，需要对模型进行优化和转换。安装完成OpenVINO后，可通过模型优化工具 <code>/opt/intel/openvino/deployment_tools/model_optimizer/mo.py</code> 进行模型优化，具体文档见Intel官方文档：  <a href="https://docs.openvinotoolkit.org/2020.3/_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html" target="_blank" rel="noopener noreferrer">Model Optimizer Developer Guide<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 。</p> <p>优化完成模型后，需要进行模型转换到Blob格式，才能在OpenNCC上进行部署。在OpenVINO安装目录 <code>/opt/intel/openvino/deployment_tools/inference_engine/lib/intel64</code>下的myriad_compile工具，使用方法如下：
命令行终端下输入：<code>/opt/intel/openvino_2020.3.194/deployment_tools/inference_engine/lib/intel64/myriad_compile -m input_xxx-fp16.xml -o output_xxx.blob -VPU_MYRIAD_PLATFORM VPU_MYRIAD_2480 -VPU_NUMBER_OF_SHAVES 6 -VPU_NUMBER_OF_CMX_SLICES 6</code> , 完成格式转换后，可在OpenNCC上部署模型，可参考：ncc_SDK/Samples/How_to/load a model，或者使用OpenView界面程序添加模型来部署测试。</p> <h2 id="openncc运行机制"><a href="#openncc运行机制" class="header-anchor">#</a> OpenNCC运行机制</h2> <p> 从一个模型训练环境到嵌入式部署，是一个非常重要的工作，需要对深度学习的框架掌握，如常用的：Caffe*, TensorFlow*, MXNet*, Kaldi* 等。此外掌握部署的嵌入式平台非常重要，需要了解平台性能，系统架构特点，结合平台特点需要对训练的模型框架进行优化，并最后调优移植部署到嵌入式平台。OpenNCC专注于深度学习模型的快速部署，兼容Intel OpenVINO，并针对嵌入式图形图像应用场景，在端侧完成了从2MP到20MP不同分辨率传感器集成，端侧实现了可部署专业级别的ISP，可将OpenVINO优化转换后的模型文件动态下载到端侧OpenNCC相机，实现深度学习模型的快速部署。同时OpenNCC设计了独立工作模式、混合开发模式和协处理计算棒模式来适配不同的工作应用场景。</p> <h3 id="openncc独立模式"><a href="#openncc独立模式" class="header-anchor">#</a> OpenNCC独立模式</h3> <p> 独立模式下，OpenNCC独立运行一个深度学习模型，并将推理结果通过OpenNCC SDK API反馈给用户。</p> <p>应用程序部署流程如下图：</p> <p><img src="/openncc/docimg/ch/SoftManualF2.png" alt="F">
按照OpenVINO文档，为特定的训练框架<a href="https://docs.openvinotoolkit.org/2020.3/_docs_MO_DG_prepare_model_Config_Model_Optimizer.html" target="_blank" rel="noopener noreferrer">配置模型优化器(Configure Model Optimizer)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p><a href="https://docs.openvinotoolkit.org/2020.3/_docs_IE_DG_Introduction.html#MO" target="_blank" rel="noopener noreferrer">运行模型优化器(Model Optimizer)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>，基于训练好的网络拓扑、权值和偏差值等可选参数产生一个优化后的IR文件，IR是一对描述整个模型的文件，包括.xml文件--拓扑文件-描述网络拓扑的XML文件，以及.bin文件--训练后的数据文件-一个包含权重并偏置二进制数据的.bin文件，然后再运行myriad_compile将IR文件生成BLOB文件。</p> <p> 在应用程序上，集成使用OpenNCC SDK下载优化完成后的BLOB模型文件，见SDK下<code>Example/How_to/Load_a_model</code>的演示程序。</p> <p> OpenNCC View是集成了OpenNCC SDK的带操作界面的应用演示程序，也可以使用OpenView来部署模型，获取测试结果。OpenNCC View 使用文档。由于不同的深度模型有差异化的推理输出结果，OpenNCC SDK对不同格式结果支持在不断增加中，如果用户无法在SDK下找到合适的后处理解析模型，需要自己参考<code>Example/How_to/Load_a_model</code>并结合自己应用场景来编写后处理代码。</p> <h4 id="二级模型运行支持"><a href="#二级模型运行支持" class="header-anchor">#</a> 二级模型运行支持</h4> <p>考虑到端侧算力，目前SDK多级模型支持到两级模型级联，如图：</p> <p><img src="/openncc/docimg/ch/SoftManualF10.jpg" alt="F"></p> <p>第一级模型必须为目标检测或者分类模型，且输出定义如下：
<img src="/openncc/docimg/ch/SoftManualF11.jpg" alt="F"></p> <p>推理流程：</p> <p>1）图像先经过Pre-cv[1] ，把原图scale到一级模型输入大小，并做相应的格式转换，然后做一级模型推理计算，并且把一级推理结果输出到Pre-cv[2].
2) Pre-cv[2] 模块解析第一级模型的推理结果，把符合条件的label和conf的检测目标，根据坐标起点(x_min, y_min), 终点(x_max,y_max)从
原图crop和scale到二级模型输入大小，并做相应的格式转换，进入第二级模型推理。</p> <p>3)最后把一级模型和全部的二级模型推理结果打包在一起输出。</p> <p>模型输出解析（图示参数配置为，有效label：2,3，conf=0.8）：</p> <p><img src="/openncc/docimg/ch/SoftManualF12.png" alt="F"></p> <p>示例程序：<code>Example/How_to/work_with_multiple_models</code>,第一级模型为车辆和车牌检测，第二级模型是车牌检测，设置有效的label为2。</p> <p>基于第一级的检测结果，适当微调第一级的检测坐标，有利于识别:</p> <p>*起点向左上方微调（startXAdj，startYAdj ）</p> <p>*底点向右下方微调（endXAdj，endYAdj）</p> <p>cnn2PrmSet.startXAdj  = -5;</p> <p>cnn2PrmSet.startYAdj  = -5;</p> <p>cnn2PrmSet.endXAdj   = 5;</p> <p>cnn2PrmSet.endYAdj   = 5;</p> <h3 id="openncc-混合模式"><a href="#openncc-混合模式" class="header-anchor">#</a> OpenNCC 混合模式</h3> <p> 当需要解决一些复杂应用场景，需要多个网络模型组合处理、OpenNCC端侧计算性能无法满足、或者端侧处理完成后需要到边缘侧集中后处理时，往往需要进行系统扩增。将实时性诉求高的模型运行在OpenNCC端侧，其他模型运行在后处理边缘机或云端。</p> <p>如图，Model-1运行在OpenNCC端侧，完成对视频流的前处理。OpenNNC将一级处理模型结果返回用户应用程序，Model-1和Model-2完全运行于OpenVINO推理引擎下，实现后续处理。</p> <p><img src="/openncc/docimg/ch/SoftManualF3.png" alt="F"> <code>Examples/Linkage_demo/work_with_OpenVINO</code> 演示了如何让OpenNCC和Host PC上OpenVINO组合实现一个分布式AI系统。</p> <h3 id="协处理计算棒模式"><a href="#协处理计算棒模式" class="header-anchor">#</a> 协处理计算棒模式</h3> <p> OpenNCC的协处理模式，类似与Intel NCS2计算棒。这种工作模式下，OpenNCC的视觉传感器不工作，用户可以单独使用OpenNCC 来实现完全兼容OpenVINO环境。OpenVINO典型的深度学习模型部署流程如下：
<img src="/openncc/docimg/ch/SoftManualF4.png" alt="F"></p> <p>按照OpenVINO文档，为特定的训练框架<a href="https://docs.openvinotoolkit.org/2020.3/_docs_MO_DG_prepare_model_Config_Model_Optimizer.html" target="_blank" rel="noopener noreferrer">配置模型优化器(Configure Model Optimizer)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>产生一个优化后的IR文件，基于训练好的网络拓扑、权值和偏差值等可选参数。</p> <p>将优化生成的IR文件下载到OpenNCC上运行<a href="https://docs.openvinotoolkit.org/2020.3/_docs_IE_DG_Introduction.html#IE" target="_blank" rel="noopener noreferrer">推理引擎(Inference Engine)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>，具体参考OpenVINO文档：<a href="https://docs.openvinotoolkit.org/2019_R1.1/_inference_engine_samples_validation_app_README.html" target="_blank" rel="noopener noreferrer">Inference Engine validation application<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 和 <a href="https://docs.openvinotoolkit.org/2020.3/_docs_IE_DG_Samples_Overview.html" target="_blank" rel="noopener noreferrer">sample applications<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 。
将<code>Source/Firmware/fw /usb-ma2x8x.mvcmd</code>复制并且替换openvino安装目录下的openvino/inference_engine/lib/intel64/usb-ma2x8x.mvcmd.(备注：替换前必须备份usb-ma2x8x.mvcmd，使用NCS2推理时需要恢复该文件)</p> <h3 id="独立模式和协处理模式区别"><a href="#独立模式和协处理模式区别" class="header-anchor">#</a> 独立模式和协处理模式区别</h3> <p> 如下图右侧是OpenNCC的独立模式，左侧是OpenNCC的协处理模式(类同Intel NCS2)。</p> <p><img src="/openncc/docimg/ch/SoftManualF5.png" alt="F">
当我们需要部署一个基于视觉的深度学习模型时，首先我们需要获取一个高质量的视频流，然后运行推理引擎来把输入的图像数据进行计算，最后输出结果。左侧的协处理模式，我们需要一个OpenNCC 或者Intel NCS2实现端侧推理，同时我们需要从一个摄像机获取视频流，并将视频帧通过USB发送给OpenNCC。而右侧的独立模式，不需要额外的摄像机来获取视频流，我们只需要将模型下载到OpenNCC后，就可以获取到推演结果。</p> <p>参考OpenVINO官网：https://docs.openvinotoolkit.org/</p></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/openncc/ch/4_NccView_ch.html" class="prev">
        OpenNCC View说明
      </a></span> <span class="next"><a href="/openncc/ch/6_SdkApi_ch.html">
        OpenNCC SDK接口文档
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/openncc/assets/js/app.92ec51d4.js" defer></script><script src="/openncc/assets/js/2.bef35a51.js" defer></script><script src="/openncc/assets/js/21.0fb2149e.js" defer></script>
  </body>
</html>
