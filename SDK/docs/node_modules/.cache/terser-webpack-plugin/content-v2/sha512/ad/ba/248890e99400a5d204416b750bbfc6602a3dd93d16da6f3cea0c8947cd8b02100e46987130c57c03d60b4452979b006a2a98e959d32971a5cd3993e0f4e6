{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{362:function(e,t,o){\"use strict\";o.r(t);var n=o(42),i=Object(n.a)({},(function(){var e=this,t=e.$createElement,o=e._self._c||t;return o(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":e.$parent.slotKey}},[o(\"h2\",{attrs:{id:\"_1-overview\"}},[o(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_1-overview\"}},[e._v(\"#\")]),e._v(\" 1. Overview\")]),e._v(\" \"),o(\"p\",[e._v(\"This document introduces the basic concepts of OpenNCC deployment, OpenNCC CDK and OpenVINO, and the method of using OpenNCC CDK to develop and deploy OpenNCC DK independent operation mode and mixed mode with OpenVINO.\")]),e._v(\" \"),o(\"h3\",{attrs:{id:\"_1-1-support-platform\"}},[o(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_1-1-support-platform\"}},[e._v(\"#\")]),e._v(\" 1.1 Support platform\")]),e._v(\" \"),o(\"p\",[e._v(\"Hardware：OpenNCC USB, OpenNCC IPC, or OpenNCC IR+，\\n PC OS：Ubuntu16.04, Ubuntu18.04, Raspberry Pi OS, ARM Linux (Need to provide toolchain cross compilation)\\n Support language: C/C++、Python3.5、Python3.7\\nOpenVINO: 2019.R1.144\")]),e._v(\" \"),o(\"h3\",{attrs:{id:\"_1-2-customer-support-center\"}},[o(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_1-2-customer-support-center\"}},[e._v(\"#\")]),e._v(\" 1.2 Customer Support Center\")]),e._v(\" \"),o(\"p\",[e._v(\"Please visit  https://www.openncc.com for more updates.\")]),e._v(\" \"),o(\"h2\",{attrs:{id:\"_2-cdk-introduction\"}},[o(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_2-cdk-introduction\"}},[e._v(\"#\")]),e._v(\" 2. CDK Introduction\")]),e._v(\" \"),o(\"p\",[e._v(\"OpenNCC CDK is a set of toolkits specifically developed for OpenNCC cameras for rapid deployment of deep learning in OpenNCC devices.\")]),e._v(\" \"),o(\"h3\",{attrs:{id:\"_2-1-cdk-development-package-directory-structure\"}},[o(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_2-1-cdk-development-package-directory-structure\"}},[e._v(\"#\")]),e._v(\" 2.1 CDK development package directory structure\")]),e._v(\" \"),o(\"table\",[o(\"thead\",[o(\"tr\",[o(\"th\",[e._v(\"Contents\")]),e._v(\" \"),o(\"th\",[e._v(\"abstract\")])])]),e._v(\" \"),o(\"tbody\",[o(\"tr\",[o(\"td\",[e._v(\"ncc_cdk/Docs\")]),e._v(\" \"),o(\"td\",[e._v(\"OpenNCC Offline documentation\")])]),e._v(\" \"),o(\"tr\",[o(\"td\",[e._v(\"ncc_cdk/NCC_View/Linux\")]),e._v(\" \"),o(\"td\",[e._v(\"OpenNCC View for Linux\")])]),e._v(\" \"),o(\"tr\",[o(\"td\",[e._v(\"ncc_cdk/Public/Firmwares\")]),e._v(\" \"),o(\"td\",[e._v(\"OpeNCC Firmware file\")])]),e._v(\" \"),o(\"tr\",[o(\"td\",[e._v(\"ncc_cdk/Public/Library/For_C&C++/Linux\")]),e._v(\" \"),o(\"td\",[e._v(\"C/C++ OpenNCC CDK static library on Linux and VPU USB bootloader\")])]),e._v(\" \"),o(\"tr\",[o(\"td\",[e._v(\"ncc_cdk/Public/Library/For_C&C++/Windows\")]),e._v(\" \"),o(\"td\",[e._v(\"C/C++ OpenNCC CDK static library on Windows and VPU USB bootloader\")])]),e._v(\" \"),o(\"tr\",[o(\"td\",[e._v(\"ncc_cdk/Public/Library/For_Python\")]),e._v(\" \"),o(\"td\",[e._v(\"Python version OpenNCC CDK package, and demo program\")])]),e._v(\" \"),o(\"tr\",[o(\"td\",[e._v(\"ncc_cdk/Sample/Demo/Hello_NCC\")]),e._v(\" \"),o(\"td\",[e._v(\"C/C++ && Python demo program, using NCC camera to output video stream\")])]),e._v(\" \"),o(\"tr\",[o(\"td\",[e._v(\"ncc_cdk/Samples/How_to/Capture video\")]),e._v(\" \"),o(\"td\",[e._v(\"Sample program, use OpenNCC CDK library to get video stream\")])]),e._v(\" \"),o(\"tr\",[o(\"td\",[e._v(\"ncc_cdk/Samples/How_to/load a model\")]),e._v(\" \"),o(\"td\",[e._v(\"Sample program, using the OpenNCC CDK library to load a deep learning model in Blob format\")])]),e._v(\" \"),o(\"tr\",[o(\"td\",[e._v(\"ncc_cdk/Samples/Demo/work with OpenVINO\")]),e._v(\" \"),o(\"td\",[e._v(\"Sample program, using OpenNCC CDK library to make OpenNCC camera integration compatible with OpenVINO\")])]),e._v(\" \"),o(\"tr\",[o(\"td\",[e._v(\"ncc_cdk/Tools/myriad_compiler\")]),e._v(\" \"),o(\"td\",[e._v(\"IR file conversion Blob file tool\")])]),e._v(\" \"),o(\"tr\",[o(\"td\",[e._v(\"ncc_cdk/Tools/deployment\")]),e._v(\" \"),o(\"td\",[e._v(\"OpenNCC deployment script\")])])])]),e._v(\" \"),o(\"p\",[e._v(\"*Link:\"),o(\"br\"),e._v(\"\\nDownload \"),o(\"RouterLink\",{attrs:{to:\"/download_links.html\"}},[e._v(\"CDK Release packet\")]),o(\"br\"),e._v(\"\\nAPI reference \"),o(\"RouterLink\",{attrs:{to:\"/Openncc_sdk_api.html\"}},[e._v(\"OpenNCC API\")])],1),e._v(\" \"),o(\"h2\",{attrs:{id:\"_3-openvino-installation-and-getting-start\"}},[o(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_3-openvino-installation-and-getting-start\"}},[e._v(\"#\")]),e._v(\" 3. OpenVINO installation and getting start\")]),e._v(\" \"),o(\"p\",[e._v(\"   To deploy a deep learning model on end-point target devices, you need to optimize and convert a trained model to the VPU characteristics to achieve higher operating performance. OpenNCC is compatible with OpenVINO's tool set and model format, and needs to rely on Intel OpenVINO's model optimizer to complete model optimization and conversion into Blob format. When using OpenNCC CDK, you need to install OpenVINO as follows:\\nIf you need to convert the trained model yourself, you need to install OpenVINO to run the model optimizer.\\nWhen OpenVINO runs in a mixed mode with the OpenVINO inference engine, it also needs OpenVINO support.\")]),e._v(\" \"),o(\"h3\",{attrs:{id:\"_3-1-download-and-install-openvino\"}},[o(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_3-1-download-and-install-openvino\"}},[e._v(\"#\")]),e._v(\" 3.1 Download and install OpenVINO\")]),e._v(\" \"),o(\"p\",[e._v(\"  OpenNCC currently supports OpenVINO version: 2019R1.144,you could \"),o(\"RouterLink\",{attrs:{to:\"/download_links.html\"}},[e._v(\"download here.\")]),o(\"br\"),e._v(\"\\n  OpenVINO installation reference \"),o(\"RouterLink\",{attrs:{to:\"/openvino_install.html\"}},[e._v(\"here\")])],1),e._v(\" \"),o(\"h3\",{attrs:{id:\"_3-2-intel-free-model-download\"}},[o(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_3-2-intel-free-model-download\"}},[e._v(\"#\")]),e._v(\" 3.2 Intel Free model download\")]),e._v(\" \"),o(\"p\",[e._v(\"  OpenNCC supports OpenVINO models, Intel has a large number of free trained models for learning reference and testing. After we have installed OpenVINO, we can use the Intel download tool to download the model collection. Model download tool path: openvino/deployment_tools/tools/model_downloader/downloader.py, common commands are as follows:\")]),e._v(\" \"),o(\"ul\",[o(\"li\",[e._v(\"View all downloadable models：./downloader.py --print\")]),e._v(\" \"),o(\"li\",[e._v(\"Download the specified model：./downloader.py --name *\")])]),e._v(\" \"),o(\"p\",[e._v(\"For example, download a face detection model ：./downloader.py --name face-detection-adas-0001-fp16\"),o(\"br\"),e._v(\" \"),o(\"img\",{attrs:{src:\"/OpenNCC-SDK/docimg/sw_figure1.png\",alt:\"Figure-1\"}})]),e._v(\" \"),o(\"h3\",{attrs:{id:\"_3-3-model-optimization-and-format-conversion\"}},[o(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_3-3-model-optimization-and-format-conversion\"}},[e._v(\"#\")]),e._v(\" 3.3 Model optimization and format conversion\")]),e._v(\" \"),o(\"p\",[e._v(\" When we need to deploy a trained model to OpenNCC, we need to optimize and transform the model. After installing OpenVINO, you can use the model optimization tool: /opt/intel/openvino/deployment_tools/model_optimizer/mo.py to optimize the model. For specific documents, see the official Intel documents: Model Optimizer Developer Guide.\"),o(\"br\"),e._v(\"\\n After the model optimization is completed, the model needs to be converted to the Blob format before it can be deployed on OpenNCC. In the OpenVINO installation directory: /opt/intel/openvino/deployment_tools/inference_engine/lib/intel64myriad_compile tool, the method of use is as follows:\\nEnter from the command line terminal：./myriad_compile -m input_xxx-fp16.xml  -o output_xxx.blob  -VPU_PLATFORM VPU_2480 -VPU_NUMBER_OF_SHAVES  8  -VPU_NUMBER_OF_CMX_SLICES 8\"),o(\"br\"),e._v(\"\\n  After the format conversion is completed, the model can be deployed on OpenNCC, refer to: ncc_cdk/Samples/How_to/load a model, or use the OpenNCC View interface program to add the model to deploy and test it.\")]),e._v(\" \"),o(\"h2\",{attrs:{id:\"_4-openncc-operating-mechanism\"}},[o(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_4-openncc-operating-mechanism\"}},[e._v(\"#\")]),e._v(\" 4. OpenNCC operating mechanism\")]),e._v(\" \"),o(\"p\",[e._v(\"  From a model training environment to embedded deployment, it is a very important task, which requires mastering the framework of deep learning, such as commonly used: Caffe*, TensorFlow*, MXNet*, Kaldi*, etc.In addition, it is very important to master the deployed embedded platform. You need to understand the platform performance, system architecture characteristics, and then combine the platform characteristics to optimize the training model framework, and finally tune, transplant, and deploy to the embedded platform.\"),o(\"br\"),e._v(\"\\n  OpenNCC focuses on the rapid deployment of deep learning models, is compatible with Intel OpenVINO tools, and for embedded graphics and image application scenarios, it has completed the integration of different resolution sensors from 2MP to 20MP on end-point target devices, and the end-point target devices has realized the deployment of professional-level ISP. OpenVINO optimized converted model files can be dynamically downloaded to the end-point OpenNCC camera to achieve rapid deployment of deep learning models.OpenNCC has designed independent working mode, mixed development mode and co-processing compute stick mode to adapt to different work application scenarios.\")]),e._v(\" \"),o(\"h3\",{attrs:{id:\"_4-1-openncc-standalone-mode\"}},[o(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_4-1-openncc-standalone-mode\"}},[e._v(\"#\")]),e._v(\" 4.1 OpenNCC standalone mode\")]),e._v(\" \"),o(\"p\",[e._v(\" In the independent mode, OpenNCC independently runs a deep learning model, and feeds back the inference results to the user through the OpenNCC CDK API.\\nThe application deployment process is as follows:\"),o(\"br\"),e._v(\" \"),o(\"img\",{attrs:{src:\"/OpenNCC-SDK/docimg/sw_figure2.png'\",alt:\"Figure-2\"}}),e._v(\")\"),o(\"br\"),e._v(\"\\n According to the OpenVINO documentation, for a specific training framework Configure Model Optimizer\"),o(\"br\"),e._v(\"\\n Run Model Optimizer to produce an optimized Intermediate Representation (IR) of the model based on the trained network topology, weights and biases values, and other optional parameters.\\nThe IR is a pair of files that describe the whole model:\")]),e._v(\" \"),o(\"ul\",[o(\"li\",[e._v(\".xml: The topology file - an XML file that describes the network topology\")]),e._v(\" \"),o(\"li\",[e._v(\".bin: The trained data file - a .bin file that contains the weights and biases binary data\"),o(\"br\"),e._v(\"\\nThen run myriad_compile to generate a BLOB file from the IR file.\"),o(\"br\"),e._v(\"\\nTo integrate the BLOB model file generated after optimization using OpenNCC CDK, see the demo program of Samples/How_to/Load a model under CDK.\"),o(\"br\"),e._v(\"\\n  OpenNCC View is an application demonstration program with an operating interface integrated with OpenNCC CDK. You can also use OpenView to deploy models and obtain test results. Refer to OpenNCC View Guide Because different depth models have differentiated inference output results, if users cannot find a suitable post-processing analytical model under the CDK, they need to refer to ncc_cdk/Samples/How_to/load a model and write post-processing code in combination with their own application scenarios.\")])]),e._v(\" \"),o(\"h3\",{attrs:{id:\"_4-2-openncc-mixed-mode\"}},[o(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_4-2-openncc-mixed-mode\"}},[e._v(\"#\")]),e._v(\" 4.2 OpenNCC mixed mode\")]),e._v(\" \"),o(\"p\",[e._v(\" When it is necessary to solve some complex application scenarios, multiple network model combination processing is required, OpenNCC end-point computing performance cannot be met, or the end-side processing needs to be concentrated on the edge side for post-processing, system expansion is often required. Run the models with high real-time requirements on the OpenNCC end-point, and the other models on the post-processing edge machine or cloud.\"),o(\"br\"),e._v(\"\\n As shown in the figure, Model-1 runs on the OpenNCC end-point  to complete the pre-processing of the video stream. OpenNNC returns the results of the first-level processing model to the user application. Model-1 and Model-2 fully run under the OpenVINO inference engine to implement subsequent processing.\"),o(\"br\"),e._v(\" \"),o(\"img\",{attrs:{src:\"/OpenNCC-SDK/docimg/sw_figure3.png\",alt:\"Figure-3\"}}),o(\"br\"),e._v(\"\\n In ncc_cdk/Samples/Demo/work with OpenVINO demonstrated how to combine OpenNCC and OpenVINO on Host PC to implement a distributed AI system.\")]),e._v(\" \"),o(\"h3\",{attrs:{id:\"_4-3-co-processing-compute-stick-mode\"}},[o(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_4-3-co-processing-compute-stick-mode\"}},[e._v(\"#\")]),e._v(\" 4.3 Co-processing compute stick mode\")]),e._v(\" \"),o(\"p\",[e._v(\" OpenNCC's co-processing mode is similar to Intel NCS2. In this mode of operation, OpenNCC's vision sensor does not work, and users can use OpenNCC alone to achieve full compatibility with the OpenVINO environment. The typical deep learning model deployment process of OpenVINO is as follows:\"),o(\"br\"),e._v(\" \"),o(\"img\",{attrs:{src:\"/OpenNCC-SDK/docimg/sw_figure4.png\",alt:\"Figure-4\"}}),o(\"br\"),e._v(\" \"),o(\"a\",{attrs:{href:\"https://docs.openvinotoolkit.org/2019_R1.1/_docs_MO_DG_prepare_model_Config_Model_Optimizer.html\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"Configure Model Optimizer\"),o(\"OutboundLink\")],1),e._v(\" for specific training framework according to OpenVINO documentation.\"),o(\"br\"),e._v(\"\\n Run Model Optimizer to produce an optimized Intermediate Representation (IR) of the model based on the trained network topology, weights and biases values, and other optional parameters.\"),o(\"br\"),e._v(\"\\n Download the optimized IR file to OpenNCC to run the Inference Engine. For details, refer to OpenVINO documents: \"),o(\"a\",{attrs:{href:\"https://docs.openvinotoolkit.org/2019_R1.1/_inference_engine_samples_validation_app_README.html\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"Inference Engine validation application\"),o(\"OutboundLink\")],1),e._v(\" and \"),o(\"a\",{attrs:{href:\"https://docs.openvinotoolkit.org/2019_R1.1/_docs_IE_DG_Samples_Overview.html\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"sample applications.\"),o(\"OutboundLink\")],1),o(\"br\"),e._v(\"\\n Copy Public/Firmwares/MvNCAPI-ma2480.mvcmd and replace openvino/inference_engine/lib/intel64/MvNCAPI-ma2480.mvcmd in the openvino installation directory.(Remarks: MvNCAPI-ma2480.mvcmd in the openvino installation directory must be backed up before replacement. This file needs to be restored when using NCS2 inference)\")]),e._v(\" \"),o(\"h3\",{attrs:{id:\"_4-4-difference-between-independent-mode-and-co-processing-mode\"}},[o(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_4-4-difference-between-independent-mode-and-co-processing-mode\"}},[e._v(\"#\")]),e._v(\" 4.4 Difference between independent mode and co-processing mode\")]),e._v(\" \"),o(\"p\",[e._v(\" The right side of the figure below is the independent mode of OpenNCC, and the left side is the co-processing mode of OpenNCC (similar to Intel NCS2).\"),o(\"br\"),e._v(\" \"),o(\"img\",{attrs:{src:\"/OpenNCC-SDK/docimg/sw_figure5.png'\",alt:\"Figure-5\"}}),e._v(\")\"),o(\"br\"),e._v(\"\\n When we need to deploy a vision-based deep learning model, first we need to obtain a high-quality video stream, then run the inference engine to calculate the input image data, and finally output the result. For the co-processing mode on the left, we need an OpenNCC DK or Intel NCS2 implements end-to-side reasoning. At the same time, we need to obtain a video stream from a camera and send the video frame to OpenNCC DK via USB. In the independent mode on the right, no additional camera is needed to obtain the video stream. We only need to download the model to OpenNCC to obtain the deduction results.\"),o(\"br\"),e._v(\"\\nRefer to OpenVINO official website:https://docs.openvinotoolkit.org/\")])])}),[],!1,null,null,null);t.default=i.exports}}]);","extractedComments":[]}