(window.webpackJsonp=window.webpackJsonp||[]).push([[11],{376:function(e,t,o){"use strict";o.r(t);var n=o(42),r=Object(n.a)({},(function(){var e=this,t=e.$createElement,o=e._self._c||t;return o("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[o("h2",{attrs:{id:"applicable-specifications"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#applicable-specifications"}},[e._v("#")]),e._v(" Applicable specifications")]),e._v(" "),o("p",[o("RouterLink",{attrs:{to:"/zh/DKIntroduction_zh.html"}},[e._v("OpenNCC DK")]),e._v(", OpenNCC Knight ,OpenNCC Lite, OpenNCC USB")],1),e._v(" "),o("h2",{attrs:{id:"operation-steps"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#operation-steps"}},[e._v("#")]),e._v(" Operation steps")]),e._v(" "),o("h3",{attrs:{id:"preparatory-work"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#preparatory-work"}},[e._v("#")]),e._v(" Preparatory work")]),e._v(" "),o("p",[e._v("One openncc camera, one USB 3.0 data cable with type-C interface, and one Ubuntu system computer;\nConnect the data cable to the USB 3.0 interface of the camera and the computer\n"),o("img",{attrs:{src:"/openncc/docimg/zh/GettingStartF1.jpg",alt:"Figure-1"}})]),e._v(" "),o("h3",{attrs:{id:"download-the-latest-release-package-or-source-code-of-view"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#download-the-latest-release-package-or-source-code-of-view"}},[e._v("#")]),e._v(" Download the latest release package or source code of view")]),e._v(" "),o("p",[o("RouterLink",{attrs:{to:"/DownloadLink.html"}},[e._v("DownloadLink")]),o("br"),e._v("\nIf you start with source code，you need to "),o("RouterLink",{attrs:{to:"/nccview.html"}},[e._v("Compile and run View")]),e._v(",under CDK's QT project.")],1),e._v(" "),o("h3",{attrs:{id:"start-from-run-view"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#start-from-run-view"}},[e._v("#")]),e._v(" Start from run View")]),e._v(" "),o("h4",{attrs:{id:"_1-openncc-operation-permission"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#_1-openncc-operation-permission"}},[e._v("#")]),e._v(" 1. OpenNCC operation permission")]),e._v(" "),o("p",[e._v("Enter CDK directory：Tools/deployment，run script “install_NCC_udev_rules.sh”，in the terminal,input:"),o("br"),e._v(" "),o("code",[e._v("./install_NCC_udev_rules.sh")]),o("br"),e._v("\nAfter get permission to mount the OpenNCC,you need to restart the PC.\n"),o("img",{attrs:{src:"/openncc/docimg/zh/GettingStartF2.png",alt:"Figure-2"}})]),e._v(" "),o("h4",{attrs:{id:"_2-unzip-the-openncc-view-packet-enter-it-open-a-terminal-and-input"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#_2-unzip-the-openncc-view-packet-enter-it-open-a-terminal-and-input"}},[e._v("#")]),e._v(" 2.Unzip the OpenNCC View packet，enter it，open a terminal，and input:")]),e._v(" "),o("p",[o("code",[e._v("./AppRun")]),e._v("，run the software(If can't run,please input:"),o("code",[e._v("sudo ./AppRun")]),e._v(" try again）"),o("br"),e._v("\nAfter OpenNCC View opened，now we could using the View to work with the OpenNCC camera："),o("br"),e._v("\n* Connect the OpenNCC Cam to the usb3.0 of the PC，clik "),o("code",[e._v("Get device info")]),e._v(" button to get the device's information.If successful the information of the device would displayed on the Log area,If the connection is not 3.0, please rotate the data cable connected to the type-C interface of openncc camera by 180 ° and insert it again.Clik "),o("code",[e._v("Get device info")]),e._v(" to get the device information. To make sure the log shows:"),o("code",[e._v("USB interface is 3.0")]),e._v(" ，and if shows not usb3.0,it also could be used as USB2.0.\n* Could choose one of the format from yuv420p/H.264/mjpeg，the default resolution is 1080p."),o("br"),e._v("\n* Click to load model "),o("code",[e._v("“1st network model”")]),e._v("：,select a AI model.Currently already supported more than 10 models. If 'None' is selected means no AI model would be running in OpenNCC only streaming out the video.After you download a AI model,could use ROI function to select a area where you want the AI modle to recognize the scene in the region.\n* “Model Score” It is the lowest score of the algorithm recognition, and the algorithm will select the object in the frame only after reaching it;"),o("br"),e._v("\n* ”Display Scaler” is the video display window size, you can adjust the display window resolution."),o("br"),e._v('\n* Check "show state" to select whether to display the current status information on the screen, including real-time frame rate, resolution and device ID.'),o("br"),e._v('\n* Check "inference acceleration" to select whether to enable algorithm acceleration. (must be selected before loading algorithm model)'),o("br"),e._v("\n* Click ”Start running models”，load the algorithm model and open the video stream successfully.\nRun the video stream, load the face detection algorithm, and then take a real shot:\n"),o("img",{attrs:{src:"/openncc/docimg/zh/face-detection.png",alt:"Figure-3"}})]),e._v(" "),o("h5",{attrs:{id:"_2-1-demonstration-of-secondary-model"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-demonstration-of-secondary-model"}},[e._v("#")]),e._v(" 2.1 Demonstration of secondary model")]),e._v(" "),o("ul",[o("li",[e._v("Select "),o("code",[e._v("vehicle-license-plate-detection-barrier-0106-fp16.blob")]),e._v(" from list  "),o("code",[e._v("“1st network model”")])]),e._v(" "),o("li",[e._v("After selection, the required model can be selected under '2nd network model'. At present, only one secondary model (license plate recognition) is supported in the demonstration. Users can add more.")])]),e._v(" "),o("h3",{attrs:{id:"start-with-the-sdk"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#start-with-the-sdk"}},[e._v("#")]),e._v(" Start with the SDK")]),e._v(" "),o("ol",[o("li",[o("RouterLink",{attrs:{to:"/DownloadLink.html"}},[e._v("Download OpenNCC CDK")]),e._v(",And "),o("RouterLink",{attrs:{to:"/nccview.html"}},[e._v("install dependency package")]),e._v("。")],1),e._v(" "),o("li",[e._v("Enter "),o("code",[e._v("Samples/How_to/Load a model")])]),e._v(" "),o("li",[o("code",[e._v("make clean")]),e._v(", "),o("code",[e._v("make")])]),e._v(" "),o("li",[o("code",[e._v("cd ../../bin/")])]),e._v(" "),o("li",[e._v("Connect the OpenNCC Cam with PC，and run "),o("code",[e._v("./Openncc")])])]),e._v(" "),o("h2",{attrs:{id:"demo-models-of-openncc"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#demo-models-of-openncc"}},[e._v("#")]),e._v(" Demo models of OpenNCC")]),e._v(" "),o("table",[o("thead",[o("tr",[o("th",[e._v("Model")]),e._v(" "),o("th",[e._v("Name")]),e._v(" "),o("th",[e._v("Introduction")]),e._v(" "),o("th",[e._v("Demo Application")]),e._v(" "),o("th",[e._v("Other references")])])]),e._v(" "),o("tbody",[o("tr",[o("td",[e._v("Object classification")]),e._v(" "),o("td",[e._v("classification-fp16")]),e._v(" "),o("td",[e._v("ssd_mobilenet_v1_coco model can detect almost 90 objects")]),e._v(" "),o("td",[e._v("Openncc Viewer")]),e._v(" "),o("td",[o("a",{attrs:{href:"https://docs.openvinotoolkit.org/latest/omz_models_public_ssd_mobilenet_v1_coco_ssd_mobilenet_v1_coco.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),o("OutboundLink")],1)])]),e._v(" "),o("tr",[o("td",[e._v("Face and Person detection")]),e._v(" "),o("td",[e._v("face-detection-adas-0001-fp16")]),e._v(" "),o("td",[e._v("Face detector for driver monitoring and similar scenarios. The network features a default MobileNet backbone that includes depth-wise convolutions to reduce the amount of computation for the 3x3 convolution block")]),e._v(" "),o("td",[e._v("Openncc Viewer")]),e._v(" "),o("td",[o("a",{attrs:{href:"http://docs.openvinotoolkit.org/2019_R1.1/_face_detection_adas_0001_description_face_detection_adas_0001.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),o("OutboundLink")],1)])]),e._v(" "),o("tr",[o("td"),e._v(" "),o("td",[e._v("face-detection-retail-0004-fp16")]),e._v(" "),o("td",[e._v("Face detector based on SqueezeNet light (half-channels) as a backbone with a single SSD for indoor/outdoor scenes shot by a front-facing camera")]),e._v(" "),o("td",[e._v("Openncc Viewer")]),e._v(" "),o("td",[o("a",{attrs:{href:"https://docs.openvinotoolkit.org/2019_R1.1/_face_detection_retail_0004_description_face_detection_retail_0004.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),o("OutboundLink")],1)])]),e._v(" "),o("tr",[o("td"),e._v(" "),o("td",[e._v("face-person-detection-retail-0002-fp16")]),e._v(" "),o("td",[e._v("This is a pedestrian detector based on backbone with hyper-feature + R-FCN for the Retail scenario")]),e._v(" "),o("td",[e._v("Openncc Viewer")]),e._v(" "),o("td",[o("a",{attrs:{href:"https://docs.openvinotoolkit.org/2019_R1.1/person-detection-retail-0002.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),o("OutboundLink")],1)])]),e._v(" "),o("tr",[o("td"),e._v(" "),o("td",[e._v("person-detection-retail-0013-fp16")]),e._v(" "),o("td",[e._v("This is a pedestrian detector for the Retail scenario. It is based on MobileNetV2-like backbone that includes depth-wise convolutions to reduce the amount of computation for the 3x3 convolution block")]),e._v(" "),o("td",[e._v("Openncc Viewer")]),e._v(" "),o("td",[o("a",{attrs:{href:"https://docs.openvinotoolkit.org/2019_R1.1/_person_detection_retail_0013_description_person_detection_retail_0013.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),o("OutboundLink")],1)])]),e._v(" "),o("tr",[o("td"),e._v(" "),o("td",[e._v("pedestrian-detection-adas-0002-fp16")]),e._v(" "),o("td",[e._v("Pedestrian detection network based on SSD framework with tuned MobileNet v1 as a feature extractor.")]),e._v(" "),o("td",[e._v("Openncc Viewer")]),e._v(" "),o("td",[o("a",{attrs:{href:"https://docs.openvinotoolkit.org/2019_R1.1/_pedestrian_detection_adas_0002_description_pedestrian_detection_adas_0002.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),o("OutboundLink")],1)])]),e._v(" "),o("tr",[o("td",[e._v("People, Cars, Bicycles")]),e._v(" "),o("td",[e._v("person-vehicle-bike-detection-crossroad-0078-fp16")]),e._v(" "),o("td",[e._v("Person/Vehicle/Bike detector is based on SSD detection architecture, RMNet backbone, and learnable image downscale block (like person-vehicle-bike-detection-crossroad-0066, but with extra pooling)")]),e._v(" "),o("td",[e._v("Openncc Viewer")]),e._v(" "),o("td",[o("a",{attrs:{href:"https://docs.openvinotoolkit.org/2019_R1.1/_person_vehicle_bike_detection_crossroad_0078_description_person_vehicle_bike_detection_crossroad_0078.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),o("OutboundLink")],1)])]),e._v(" "),o("tr",[o("td"),e._v(" "),o("td",[e._v("pedestrian-and-vehicle-detector-adas-0001-fp16")]),e._v(" "),o("td",[e._v("Pedestrian and vehicle detection network based on MobileNet v1.0 + SSD.")]),e._v(" "),o("td",[e._v("Openncc Viewer")]),e._v(" "),o("td",[o("a",{attrs:{href:"https://docs.openvinotoolkit.org/2019_R1.1/_pedestrian_and_vehicle_detector_adas_0001_description_pedestrian_and_vehicle_detector_adas_0001.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),o("OutboundLink")],1)])]),e._v(" "),o("tr",[o("td",[e._v("Vehicle Detection")]),e._v(" "),o("td",[e._v("vehicle-detection-adas-0002-fp16")]),e._v(" "),o("td",[e._v("This is a vehicle detection network based on an SSD framework with tuned MobileNet v1 as a feature extractor.")]),e._v(" "),o("td",[e._v("Openncc Viewer")]),e._v(" "),o("td",[o("a",{attrs:{href:"http://docs.openvinotoolkit.org/2019_R1.1/_vehicle_detection_adas_0002_description_vehicle_detection_adas_0002.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),o("OutboundLink")],1)])]),e._v(" "),o("tr",[o("td",[e._v("Mask Detect")]),e._v(" "),o("td",[e._v("Mask-detect-fp16")]),e._v(" "),o("td",[e._v("Mask detect")]),e._v(" "),o("td",[e._v("Openncc Viewer")]),e._v(" "),o("td",[e._v("Under license")])]),e._v(" "),o("tr",[o("td",[e._v("Vehicle License Plate")]),e._v(" "),o("td",[e._v("vehicle-license-plate-detection-barrier-0106-fp16")]),e._v(" "),o("td",[e._v('This is a MobileNetV2 + SSD-based vehicle and (Chinese) license plate detector for the "Barrier" use case.')]),e._v(" "),o("td",[e._v("Openncc Viewer")]),e._v(" "),o("td",[o("a",{attrs:{href:"https://docs.openvinotoolkit.org/2019_R1.1/_vehicle_license_plate_detection_barrier_0106_description_vehicle_license_plate_detection_barrier_0106.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),o("OutboundLink")],1)])]),e._v(" "),o("tr",[o("td",[e._v("Interactive face detection")]),e._v(" "),o("td",[e._v("interactive_face_detection_demo")]),e._v(" "),o("td",[e._v("This demo executes four parallel infer requests for the Age/Gender Recognition, Head Pose Estimation, Emotions Recognition, and Facial Landmarks Detection networks that run simultaneously")]),e._v(" "),o("td",[e._v("Sample/Demo/work with OpenVINO/interactive_face_detection_demo")]),e._v(" "),o("td",[o("a",{attrs:{href:"https://docs.openvinotoolkit.org/2019_R1.1/_inference_engine_samples_interactive_face_detection_demo_README.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),o("OutboundLink")],1)])]),e._v(" "),o("tr",[o("td",[e._v("Human Pose Estimation")]),e._v(" "),o("td",[e._v("human-pose-estimation-0001-fp16")]),e._v(" "),o("td",[e._v("A multi-person 2D pose estimation network (based on the OpenPose approach) with tuned MobileNet v1 as a feature extractor.")]),e._v(" "),o("td",[e._v("Sample/Demo/work with OpenVINO/human_pose_estimation_demo")]),e._v(" "),o("td",[o("a",{attrs:{href:"https://docs.openvinotoolkit.org/2019_R1.1/_human_pose_estimation_0001_description_human_pose_estimation_0001.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenVINO Doc Link"),o("OutboundLink")],1)])])])])])}),[],!1,null,null,null);t.default=r.exports}}]);